[{"categories":null,"content":"Python Tutorial of Machine-Learning Python Shell Python shell, a place where you can type Python code and immediately see the results.\nPython Shell The Python shell that\u0026rsquo;s used here is actually not the original one; we\u0026rsquo;re using IPython, short for Interactive Python(简称为交互式Python), which is some kind of juiced up version of regular Python that\u0026rsquo;ll be useful later on(Python的加强版本). IPython was created by Fernando Pérez and is part of the broader Jupyter ecosystem. Apart from interactively working with Python, you can also have Python run so called python scripts.(除了和python交互外，也可以直接运行python脚本)\nChapter 1:Basic Data Type Python has a number of basic types including integers, floats, booleans, and strings. # These data types behave in ways that are familiar from other programming languages.\nStrings 1#format strings 2str = \u0026#34;my name is %s,%dyear-old\u0026#34; % (\u0026#34;long\u0026#34;,25) 3print(str) my name is long,25 year-old  如果字符串里面有引号，那么定义字符串就应该使用不同的引号。\n里面是单引号，外面就用双引号。\n里面是双引号，外面就用单引号。\n1str1 = \u0026#34;他说：\u0026#39;你好\u0026#39;\u0026#34; 2print(str1) 3str2 = \u0026#39;他说：\u0026#34;你好\u0026#34;\u0026#39; 4print(str2) 他说：'你好' 他说：\u0026quot;你好\u0026quot;  A string can multiplied by an integer\n1print(\u0026#39;a\u0026#39;*2) 2print(\u0026#39;Long\u0026#39;*3) aa LongLongLong  Str methods capitalize():使字符串首字母大写\nreplace(old, new[, count]) -\u0026gt; str\n1sister = \u0026#39;liz\u0026#39; 2print(sister.capitalize()) 3print(sister.replace(\u0026#39;z\u0026#39;,\u0026#39;sa\u0026#39;)) Liz lisa  Complex Number Python has build-in type of complex number\n1# Create a complex number, 2ComplexNum = (12+3j) # or ues ComplexNum = complex(12,3) 3print(ComplexNum) 1#real component \u0026amp; imagine component 2print(ComplexNum.real) # print the real component 3print(ComplexNum.imag) # print the imagine component Operator The following operators are different from c language\n   operator description     ** Exponentiation(指数运算)   // 取整除    The operator behaved differently for different data types.\n\u0026ldquo;+\u0026rdquo; operator:\nFor the integers, the values were summed\nFor the strings, the strings were pasted together\n1print(1+2) 2print(\u0026#34;My first name is: \u0026#34;+\u0026#34;Long\u0026#34;) 3print(True+True) 3 My first name is: Long 2  Containers:List \u0026amp; Dictionary \u0026amp; sets \u0026amp; tuples List A list is an ordered and resizeable array of elements\nA list can contain elements of different types,almost any Python object include containers type and even function\nordered:索引序号与元素的对应关系与创建时保持一致\narray:有sequence特性\n1#Create a list 2my_list=[] #create a empty list 3my_list = [1,2,\u0026#34;too\u0026#34;] 4print(my_list) [1, 2, 'too']  1my_list1 = [1,2,3,4] 2my_list2 = [5,6] 3dictionary = {\u0026#34;age\u0026#34;:25} 4s = {\u0026#34;cat\u0026#34;,\u0026#34;dog\u0026#34;,\u0026#34;cat\u0026#34;} 5tup = (10,11) 6 7my_list1.append(my_list2) 8my_list1.append(dictionary) 9my_list1.append(s) 10my_list1.append(tup) 11print(my_list1) 12my_list2.append(7) 13print(my_list1) [1, 2, 3, 4, [5, 6], {'age': 25}, {'dog', 'cat'}, (10, 11)] [1, 2, 3, 4, [5, 6, 7], {'age': 25}, {'dog', 'cat'}, (10, 11)]  1def replace(arg): 2 arg[0] = \u0026#34;long\u0026#34; 3my_list = [1,2,3] 4my_list.append(replace) 5print(my_list) 6my_list[3](my_list) 7print(my_list) [1, 2, 3, \u0026lt;function replace at 0x7f9819b27488\u0026gt;] ['long', 2, 3, \u0026lt;function replace at 0x7f9819b27488\u0026gt;]  Indices Notice:the end of the slice is exclusive and that the index starts at zero!\nNegetive indices support\nmy_list = [1,2,\u0026ldquo;too\u0026rdquo;]\n   1 2 \u0026ldquo;too\u0026rdquo;     0 1 2   -3 -2 -1    Slicing [start:end]\n   start end     include exclude    However, it\u0026rsquo;s also possible not to specify these indexes. If you don\u0026rsquo;t specify the begin index, Python figures out that you want to start your slice at the beginning of your list. If you don\u0026rsquo;t specify the end index, the slice will go all the way to the last element of your list.\n1print(my_list[-1]) 2print(my_list[1:]) # Get a slice from index 1 to the end 1#Loop over the elements in list 2for x in my_list : 3 print(x) 4#Loop over the indices and elements 5for i,x in enumerate(my_list) : 6 print(str(i+1) + \u0026#34;:\u0026#34; +str(x)) 1#List Comprehension(列表推导式)用于创建list 2#new_list=[expression_for_member for member in iterable if condition] 3my_list=[x**2 for x in range(5) if x%2 == 0] 4print(my_list) [0, 4, 16]  1# Quick sort complementation using list 2def QuickSort(arr) : 3 if len(arr) \u0026lt;= 1 : 4 return arr 5 pivot = arr[0] 6 left = [x for x in arr if x \u0026lt; pivot] 7 middle = [x for x in arr if x == pivot] 8 right = [x for x in arr if x \u0026gt; pivot] 9 return QuickSort(left) + middle + QuickSort(right) Manipulating List List\u0026rsquo;s methods can change the objects they are called on sometime, it can also be pretty dangerous, so watch out.\n\u0026lsquo;+\u0026rsquo; operator in list Use the \u0026lsquo;+\u0026rsquo; operator in list can build a list which paste the right list to the end of the right list\nReplace list elements Replacing list elements is pretty easy. Simply subset the list and assign new values to the subset. You can select single elements or you can change entire list slices at once.\nDelete list elements you can use the \u0026lsquo;del\u0026rsquo; build-in function to remove elements from your list.\nPay attention here: as soon as you remove an element from a list, the indexes of the elements that come after the deleted element all change! 注意选项一的误导性：先删除下标10的元素，会导致原list的下标发生变化，无法得到预期的结果\n1areas = [\u0026#34;hallway\u0026#34;, 11.25, \u0026#34;kitchen\u0026#34;, 18.0, \u0026#34;chill zone\u0026#34;, 20.0, 2 \u0026#34;bedroom\u0026#34;, 10.75, \u0026#34;bathroom\u0026#34;, 10.50] 3areas_1 = areas + [\u0026#34;poolhouse\u0026#34;, 24.5] 4print(areas_1) 5areas_1[:1] = [\u0026#34;chill zone\u0026#34;,10.5] 6print(areas_1) 7del(areas_1[-2:]) 8print(areas_1) ['hallway', 11.25, 'kitchen', 18.0, 'chill zone', 20.0, 'bedroom', 10.75, 'bathroom', 10.5, 'poolhouse', 24.5] ['chill zone', 10.5, 11.25, 'kitchen', 18.0, 'chill zone', 20.0, 'bedroom', 10.75, 'bathroom', 10.5, 'poolhouse', 24.5] ['chill zone', 10.5, 11.25, 'kitchen', 18.0, 'chill zone', 20.0, 'bedroom', 10.75, 'bathroom', 10.5]  Inner workings of lists Identfier of list does not actually contain all the list elements, it rather contains a reference to the list!\nLet\u0026rsquo;s store the list x as a new variable y, by simply using the equals sign.\nLet\u0026rsquo;s now change the element with index one in the list y, like this. When you\u0026rsquo;re updating an element the list, it\u0026rsquo;s one and the same list in the computer memory your changing. Both x and y point to this list, so the update is visible from both variables. If you want to create a list y that points to a new list in the memory with the same values,you\u0026rsquo;ll need to use something else than the equals sign. You can use the list function,like this, or use slicing [:] to select all list elements explicitly.\nIf you now make a change to the list y points to, x is not affected.\nList methods index():to get t he index of a element\ncount():to count the number of a element in list\nreverse():to reverses the order of the elements in the list it is called on\n1fam = [\u0026#39;lisa\u0026#39;,1.72,\u0026#39;emma\u0026#39;,1.72] 2print(fam.index(\u0026#39;lisa\u0026#39;)) 3print(fam.count(1.72)) 0 2  Dictionary A dictionary stores (key:value)pairs\nDictionaries are inherently unordered\nthe keys in a dictionary should be unique. If you try to add another key:value pair to world with the same key, the last pair that you specified in the curly brackets was kept in the resulting dictionary.\nAlso, these unique keys in a dictionary should be so-called immutable objects.\nBasically, the content of immutable objects cannot be changed after they\u0026rsquo;re created.\nDictionaries can contain key:value pairs where the values are again dictionaries.\n1#Create a dictionary 2d = {} #create a empty dictionary 3d = {\u0026#34;name\u0026#34;:\u0026#34;zhang\u0026#34;,\u0026#34;gender\u0026#34;:\u0026#34;famale\u0026#34;,\u0026#34;height\u0026#34;:173,\u0026#34;name\u0026#34;:\u0026#34;long\u0026#34;} 4print(d) 5europe = { \u0026#39;spain\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;madrid\u0026#39;, \u0026#39;population\u0026#39;:46.77 }, 6 \u0026#39;france\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;paris\u0026#39;, \u0026#39;population\u0026#39;:66.03 }, 7 \u0026#39;germany\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;berlin\u0026#39;, \u0026#39;population\u0026#39;:80.62 }, 8 \u0026#39;norway\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;oslo\u0026#39;, \u0026#39;population\u0026#39;:5.084 } } 9print(europe) {'name': 'long', 'gender': 'famale', 'height': 173} {'spain': {'capital': 'madrid', 'population': 46.77}, 'france': {'capital': 'paris', 'population': 66.03}, 'germany': {'capital': 'berlin', 'population': 80.62}, 'norway': {'capital': 'oslo', 'population': 5.084}}  1#add or delete a pair in dictionary 2d[\u0026#34;weight\u0026#34;] = 71 3print(d) 4del(d[\u0026#34;gender\u0026#34;]) # del d[\u0026#34;gender\u0026#34;] 5print(d) {'name': 'long', 'gender': 'famale', 'height': 173, 'weight': 71} {'name': 'long', 'height': 173, 'weight': 71}  1#Loop over the keys in dictionary 2for attribute in d: 3 print(d[attribute]) 4#Loop over keys and their corresponding values,use the item() 5for attribute,value in d.items(): 6 print(\u0026#34;%s:%s\u0026#34; % (str(attribute),str(value))) 7print(\u0026#34;height\u0026#34; in d) long famale 173 name:long gender:famale height:173 True  1# dictionary comprehension 2my_list = [\u0026#34;name\u0026#34;,\u0026#34;long\u0026#34;,\u0026#34;height\u0026#34;,173] 3dictionary = {my_list[i-1]:x for i,x in enumerate(my_list) if (i+1)%2==0} 4print(dictionary) {'name': 'long', 'height': 173}  methods keys() Check out which keys are in dictionary by calling the keys() method\nList vs Dictionary The list is a sequence of values that are indexed by a range of numbers.\nThe dictionary is indexed by unique keys, that can be any immutable type.\n   List Dictionary     indexed by range of numbers indexed by unique keys   collection of values; Lookup table with unique keys   order matters;    select entire subsets     When to use which one if you have a collection of values where the order matters, and you want to easily select entire subsets of data, you\u0026rsquo;ll want to go with a list.\nIf, on the other hand, you need some sort of look up table, where looking for data should be fast and where you can specify unique keys, a dictionary is the preferred option.\n1d = {\u0026#34;name\u0026#34;:\u0026#34;long\u0026#34;,\u0026#34;gender\u0026#34;:\u0026#34;famale\u0026#34;,\u0026#34;height\u0026#34;:173} 2print(d.keys()) dict_keys(['name', 'gender', 'height'])  Set(集合) A set is an unordered collection of distinct elements\nunordered:所谓无序是指数据结构上的无序，区别于列表，即set的索引序号与元素的对应关系不一定与创建时一致\ndistinct:不重复性，set中的元素不会重复\n1#create a set 2s = set() #create a empty set,note the difference from creation of a empty dictionary 3 #set([iterable]) iterable -- 可迭代对象对象； 4s = set(\u0026#34;ddsasad\u0026#34;) 5print(s) 6s = {\u0026#34;cat\u0026#34;,\u0026#34;dog\u0026#34;,\u0026#34;fish\u0026#34;} 7print(s) 8 1#Iterating over a set has the same syntax as iterating over a list;  2#however since sets are unordered, you cannot make assumptions about the order in which you visit the elements of the set 3for i,x in enumerate(s): 4 print(str(i)+\u0026#34;:\u0026#34;+str(x)) 1# 下面展示两个集合间的运算. 2... 3\u0026gt;\u0026gt;\u0026gt; a = set(\u0026#39;abracadabra\u0026#39;) 4\u0026gt;\u0026gt;\u0026gt; b = set(\u0026#39;alacazam\u0026#39;) 5\u0026gt;\u0026gt;\u0026gt; a 6{\u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;} 7\u0026gt;\u0026gt;\u0026gt; a - b # 集合a中包含而集合b中不包含的元素 8{\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;} 9\u0026gt;\u0026gt;\u0026gt; a | b # 集合a或b中包含的所有元素 10{\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;l\u0026#39;} 11\u0026gt;\u0026gt;\u0026gt; a \u0026amp; b # 集合a和b中都包含了的元素 12{\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;} 13\u0026gt;\u0026gt;\u0026gt; a ^ b # 不同时包含于a和b的元素 14{\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;l\u0026#39;} {'b', 'd', 'l', 'm', 'r', 'z'}  1type([1,2]) 2s={\u0026#34;dsa\u0026#34;,\u0026#34;dsa\u0026#34;} 3# s.update({\u0026#34;dsa1\u0026#34;:\u0026#34;qw\u0026#34;,\u0026#34;dsa2\u0026#34;:12}) 4s |= set({\u0026#34;dsa1\u0026#34;:\u0026#34;qw\u0026#34;,\u0026#34;dsa2\u0026#34;:12}) 5print(s) {'dsa2', 'dsa', 'dsa1'}  Tuple a tuple is an immutable ordered list of values\nimmutable:tuple isn\u0026rsquo;t allowed to delete,update and add its elements.\n1# create a tuple 2tup = () # create a empty tuple 3tup = (\u0026#39;cat\u0026#39;,\u0026#34;dog\u0026#34;,1111,52) 4print(tup) ('cat', 'dog', 1111, 52)  A tuple is in many ways similar to a list;\none of the most important differences is that tuples can be used as keys in dictionaries and as elements of sets, while lists cannot.\n1dictionary = {(x-1,x):x**2 for x in range(4) if x%2==0} 2print(dictionary) {(-1, 0): 0, (1, 2): 4}  Identfier of containers jsut like the pointer in c language 1def replace(arg): 2 arg[\u0026#39;name\u0026#39;] = \u0026#34;Jinyu\u0026#34; 3dictionary = {\u0026#34;name\u0026#34;:\u0026#34;long\u0026#34;,\u0026#34;age\u0026#34;:25} 4print(dictionary) 5replace(dictionary) 6print(dictionary) {'name': 'long', 'age': 25} {'name': 'Jinyu', 'age': 25}  Numpy Numpy is a core library for scientific computing\nIt provide a high-performance multidimensional array object and tools for working with these arrays\nMotivation A list can hold any type and can hold different types at the same time. You can also change, add and remove elements,this is wonderful.However,When analyzing data, you\u0026rsquo;ll often want to carry out operations over entire collections of values, and you want to do this fast. With lists, this is a problem.\nIllustration Let\u0026rsquo;s retake the heights of your family and yourself. Suppose you\u0026rsquo;ve also asked for everybody\u0026rsquo;s weight. It\u0026rsquo;s not very polite, but everything for science, right? You end up with two lists, height, and weight. The first person is 1-point-73 meters tall and weighs 65-point-4 kilograms. If you now want to calculate the Body Mass Index for each family member, you\u0026rsquo;d hope that this call can work, making the calculations element-wise. Unfortunately, Python throws an error, because it has no idea how to do calculations on lists. You could solve this by going through each list element one after the other, and calculating the BMI for each person separately, but this is terribly inefficient and tiresome to write.\nSolution: Numpy A way more elegant solution is to use NumPy, or Numeric Python. It\u0026rsquo;s a Python package that, among others, provides a alternative to the regular python list: the Numpy array. The Numpy array is pretty similar to the list, but has one additional feature: you can perform calculations over entire arrays. It\u0026rsquo;s really easy, and super-fast as well.\n1import numpy as np 2height = [1.73, 1.68, 1.71, 1.89, 1.79] 3weight = [65.4, 59.2, 63.6, 88.4, 68.7] 4#Create a numpy array 5np_weight = np.array(weight) 6np_height = np.array(height) 7bmi = np_weight / np_height**2 8print(bmi) [21.85171573 20.97505669 21.75028214 24.7473475 21.44127836]  Numpy Subsetting you can work with Numpy arrays pretty much the same as you can with regular Python lists.\nSpecifically for Numpy, there\u0026rsquo;s also another way to do list subsetting: using an array of booleans.\nA first step is using the comparsion Operators\nThe result is a Numpy array containing booleans: True if the corresponding elements comform the comparsion condition,False if it\u0026rsquo;s not.\nNext, you can use this boolean array inside square brackets to do subsetting,so for which the corresponding boolean value is True, is selected.\nTypically, Python can\u0026rsquo;t tell how two objects with different types relate.(通常来说python不能进行两种不同数据类型的比较)\nBehind the scenes, Numpy builds a numpy array of the same size filled with the number and then performs an element-wise comparison.\n1is_lightweight = bmi \u0026lt;21 2print(bmi[is_lightweight]) [20.97505669]  Numpy: remarks Numpy array can only contain values of a single type. It\u0026rsquo;s either an array of floats, either an array of booleans, and so on.\nIf you do try to create an array with different types,the resulting Numpy array will contain a single type:\nThe boolean,the string and the float were both converted to strings.\nThe boolean and the float were both converted to float,\u0026lsquo;True\u0026rsquo; convert to \u0026lsquo;1\u0026rsquo;, and \u0026lsquo;False\u0026rsquo; convert to \u0026lsquo;0\u0026rsquo;\n1print(np.array([1.0, \u0026#34;is\u0026#34;, True])) 2print(np.array([1.0, False, True])) 3print(np.array([True, 1, 2]) + np.array([3, 4, False])) ['1.0' 'is' 'True'] [1. 0. 1.] [4 5 2]  Numpy boolen operato If you combine two numpy array with the and operator,it will induce a error.\nprint(bmi \u0026lt; 22 and bmi \u0026gt; 21)\nAfter some digging in the numpy documentation, you can find the functions logical_and, logical_or and logical_not, the \u0026ldquo;array equivalents\u0026rdquo; of and or and not.\n1print(np.logical_and(bmi \u0026lt; 22,bmi \u0026gt; 21)) 2print(bmi[np.logical_and(bmi \u0026lt; 22,bmi \u0026gt; 21)]) [ True False True False True] [21.85171573 21.75028214 21.44127836]  2D Numpy Arrays Type of Numpy Arrays If you ask for the type of these arrays, Python tells you that they are numpy.ndarray. numpy dot tells you it\u0026rsquo;s a type that was defined in the numpy package. ndarray stands for n-dimensional array.\nit\u0026rsquo;s perfectly possible to create 2 dimensional, three dimensional, heck even seven dimensional arrays!\n2D Numpy Arrays You can create a 2D numpy array from a regular Python list of lists.\nit is a rectangular data structure: Each sublist in the list, corresponds to a row in the two dimensional numpy array.\n\u0026lsquo;shape\u0026rsquo; is a so-called attribute of the numpy array, that can give you dimensional information of numpy array.\nSubsetting Basically you\u0026rsquo;re selecting the row, and then from that row do another selection. There\u0026rsquo;s also an alternative way of subsetting, using single square brackets and a comma. This call returns the exact same value as before. The value before the comma specifies the row, the value after the comma specifies the column.The intersection of the rows and columns you specified, are returned.\nOnce you get used to it, this syntax is more intuitive and opens up more possibilities.\nBy using slice,The intersection can gives us a 2D array\nThe \u0026lsquo;:\u0026rsquo; is for slicing, it tells Python to include some rows or columns.\n1np_2d = np.array([[1.73, 1.68, 1.71, 1.89, 1.79],\\ 2 [65.4, 59.2, 63.6, 88.4, 68.7]]) 3print(np_2d.shape) 4print(np_2d[1][0]) 5print(np_2d[1,0]) 6print(np_2d[:,:2]) (2, 5) 65.4 65.4 [[ 1.73 1.68] [65.4 59.2 ]]  2D Arithmetic 2D numpy arrays enable you to do element-wise calculations, the same way you did it with 1D numpy arrays.\nYou can combine matrices with single numbers, with vectors, and with other matrices.\n1import numpy as np 2np_mat = np.array([[1, 2], 3 [3, 4], 4 [5, 6]]) 5print(np_mat * 2) 6print(np_mat + np.array([10, 10])) # equal to \u0026#34;np_mat + 10\u0026#34; 7print(np_mat + np_mat) [[ 2 4] [ 6 8] [10 12]] [[11 12] [13 14] [15 16]] [[ 2 4] [ 6 8] [10 12]]  Difference Between array and matrix in numpy matrix是array的分支\nDimension numpy array(ndarrays) can be N-dimension\nnumpy matrix must be 2-dimension\n注意：\n1.一维的numpy数组不是向量或矩阵,此时shape属性中是没有列值的,如果需要当作向量来操,可以使用list of list来生成array\n2.matrix和array在很多时候都是通用的，由于array可以表示更高维度的数据，更灵活，速度更快，官方建议选择array,必要时再转换成matrix\nAttribute numpy array和matrix 都有.T属性来表示它们的转置\nmatrix还有.H属性表示共轭转置,.I表示逆矩阵\nMethod 两者可以互相用.asmatrix()或.asarray()互相转换\n1import numpy as np 2arr = np.array([1,2,3]) # arr 不算矩阵 3print(arr.shape) 4print(arr.T.shape) 5 6mat = np.mat([1,2,3]) 7print(mat.shape) 8print(mat.T.shape) (3,) (3,) (1, 3) (3, 1)  Operation array numpy array 大多数操作符号都是element-wise的,比如*操作和np.multiply()函数,都是对应元素相乘(element-wise multiplication)\n例如：\n$$ x = \\begin{bmatrix} 1 \u0026amp; 2\\\n3 \u0026amp; 4 \\end{bmatrix}, y=\\begin{bmatrix} 1 \\ 2 \\end{bmatrix}, z=\\begin{bmatrix} 1 \u0026amp; 2 \\end{bmatrix}$$ $$ xy=\\begin{bmatrix} 1 \u0026amp; 2\\\n6 \u0026amp; 8 \\end{bmatrix}, xz=\\begin{bmatrix} 1 \u0026amp; 4\\\n3 \u0026amp; 8 \\end{bmatrix} $$\n对应元素相乘一般需要向量的行或列与矩阵相等,或者两个矩阵行与列相等\n@操作和.dot()方法或np.dot()函数,进程矩阵乘法\nmatrix matrix的优势就是相对简单的运算符号,可以直接用*操作表示矩阵乘法,但是也兼容array的函数和方法\n1x = np.array([ [1,2],[3,4] ]) 2y = np.array([[1,2]]) 3print(y.shape) 4print(x*y.T) 5print(np.multiply(x,y)) (1, 2) [[1 2] [6 8]] [[1 4] [3 8]]  Numpy: Basic Statistics However, the big difference here is speed. Because Numpy enforces a single data type in an array, it can drastically speed up the calculations.\nMotivation:to know your data A typical first step in analyzing your data is getting to know your data in the first place.\nAs a data scientist, you\u0026rsquo;ll be crunching thousands, if not millions or billions of numbers.\nWhat you can do, though, is generate summarizing statistics about your data.\nMotivation:to do sanity check Often, these summarizing statistics will provide you with a \u0026ldquo;sanity check\u0026rdquo; of your data. If you end up with a average weight of 2000 kilograms, your measurements are most likely incorrect.\nsanity check:数据的健全性检查，通过平均值、中位数和标准差等统计数据来检查数据中是否存在异常值等问题\nmean value you can try to find out the average value of your data set, with Numpy\u0026rsquo;s mean() function.\nBecause it\u0026rsquo;s a function from the Numpy package, don\u0026rsquo;t forget to start with np\nmedian median is the middle value if you sort all data from small to big.\nyou can simply use Numpy\u0026rsquo;s \u0026lsquo;median()\u0026rsquo; function\nmore function in numpy corrcoeff():to check if for example height and weight are correlated\nstd():for standard deviation\nand so on,such as sum and sort, which also exist in the basic Python distribution.\nGenerate data Just a sidenote here: If you\u0026rsquo;re wondering how I came up with the data in this video: We simulated it with Numpy functions! I sampled two random distributions 5000 times to create the height and weight arrays, and then used column_stack to paste them together as two columns. Another awesome thing that Numpy can do! Another great tool to get some sense of your data is to visualize it, but that\u0026rsquo;s something for the next course also.\n1# help(np.random.normal) 2#用于抽取服从正态分布的样本 3#arg1:样本均值；arg2:样本标准差；arg3:样本个数 4np_height_cm = np.round(np.random.normal(1.75,0.2,20),2) 5np_weight_kg = np.round(np.random.normal(60.32,15,20),2) 6# help(np.column_stack) 7# Stack 1-D arrays as columns into a 2-D array. 8# arg1:包含array的tup 9np_city = np.column_stack((np_height_cm,np_weight)) 10print(np.mean(np_height_cm)) 11print(np.median(np_height_cm)) 12print(np.std(np_height_cm)) 13print(np.corrcoef(np_city[:,0],np_city[:,1])) 1.8544999999999998 1.85 0.16524148994728896 [[1. 0.2840335] [0.2840335 1. ]]  Outlier however, you notice that some height values are abnormally high.\nMean value and median as summary statistic is best suited if you\u0026rsquo;re dealing with so-called outliers.\n1np_height_cm = np.array([1.64 ,1.49 ,1.79 ,18.4 ,20.7 ,177 ,1.72 ,1.61]) 2print(np.mean(np_height_cm)) 3print(np.median(np_height_cm)) 28.04375 1.755  Exercise You\u0026rsquo;ve contacted FIFA for some data and they handed you two lists. The lists are the following:\npositions = ['GK', 'M', 'A', 'D', ...] heights = [191, 184, 185, 180, ...]\nEach element in the lists corresponds to a player. The first list, positions, contains strings representing each player\u0026rsquo;s position. The possible positions are: 'GK' (goalkeeper), 'M' (midfield), 'A' (attack) and 'D' (defense). The second list, heights, contains integers representing the height of the player in cm. The first player in the lists is a goalkeeper and is pretty tall (191 cm).\nYou\u0026rsquo;re fairly confident that the median height of goalkeepers is higher than that of other players on the soccer field. Some of your friends don\u0026rsquo;t believe you, so you are determined to show them using the data you received from FIFA and your newly acquired Python skills.\n1heights = [191, 184, 185, 180, 181, 187, 170, 179, 183, 186, 185, 170, 187, 183, 173, 188, 183, 180, 188, 175, 193, 180, 185, 170, 183, 173, 185, 185, 168, 190] 2positions = [\u0026#39;GK\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;GK\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;GK\u0026#39;] 3np_positions = np.array(positions) 4np_heights = np.array(heights) 5gk_heights = np_heights[np_positions == \u0026#39;GK\u0026#39;] 6other_heights = np_heights[np_positions != \u0026#39;GK\u0026#39;] 7print(\u0026#34;Median height of goalkeepers: \u0026#34; + str(np.median(gk_heights))) 8print(\u0026#34;Median height of other players: \u0026#34; + str(np.median(other_heights))) Median height of goalkeepers: 191.0 Median height of other players: 183.0  Matplotlib There are many visualization packages in python, but the mother of them all, is matplotlib.\nMotivation Data visualization, which is a very important part of data analysis. First of all, you will use it to explore your dataset. The better you understand your data, the better you\u0026rsquo;ll be able to extract insights. And once you\u0026rsquo;ve found those insights, again, you\u0026rsquo;ll need visualization to be able to share your valuable insights with other people.\npyplot pyplot is a subpackage of Matplotlib\nBy convention, this subpackage is imported as plt\nimport matplotlib.pyplot as plt\nplot line chart(绘制折线图) we call plt.plot() and use our two lists as arguments.\nThe first argument corresponds to the horizontal axis, and the second one to the vertical axis.\nThere are several data points, and Python draws a line between them.\nIf you pass only one argument, Python will know what to do and will use the index of the list to map onto the x axis, and the values in the list onto the y axis.\nplt.show() You might think that a plot will pop up right now, but Python\u0026rsquo;s pretty lazy. It will wait for the show() function to actually display the plot. This is because you might want to add some extra ingredients to your plot before actually displaying it, such as titles and label customizations.\n1import matplotlib.pyplot as plt 2year = [1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100] 3pop = [2.53, 2.57, 2.62, 2.67, 2.71, 2.76, 2.81, 2.86, 2.92, 2.97, 3.03, 3.08, 3.14, 3.2, 3.26, 3.33, 3.4, 3.47, 3.54, 3.62, 3.69, 3.77, 3.84, 3.92, 4.0, 4.07, 4.15, 4.22, 4.3, 4.37, 4.45, 4.53, 4.61, 4.69, 4.78, 4.86, 4.95, 5.05, 5.14, 5.23, 5.32, 5.41, 5.49, 5.58, 5.66, 5.74, 5.82, 5.9, 5.98, 6.05, 6.13, 6.2, 6.28, 6.36, 6.44, 6.51, 6.59, 6.67, 6.75, 6.83, 6.92, 7.0, 7.08, 7.16, 7.24, 7.32, 7.4, 7.48, 7.56, 7.64, 7.72, 7.79, 7.87, 7.94, 8.01, 8.08, 8.15, 8.22, 8.29, 8.36, 8.42, 8.49, 8.56, 8.62, 8.68, 8.74, 8.8, 8.86, 8.92, 8.98, 9.04, 9.09, 9.15, 9.2, 9.26, 9.31, 9.36, 9.41, 9.46, 9.5, 9.55, 9.6, 9.64, 9.68, 9.73, 9.77, 9.81, 9.85, 9.88, 9.92, 9.96, 9.99, 10.03, 10.06, 10.09, 10.13, 10.16, 10.19, 10.22, 10.25, 10.28, 10.31, 10.33, 10.36, 10.38, 10.41, 10.43, 10.46, 10.48, 10.5, 10.52, 10.55, 10.57, 10.59, 10.61, 10.63, 10.65, 10.66, 10.68, 10.7, 10.72, 10.73, 10.75, 10.77, 10.78, 10.79, 10.81, 10.82, 10.83, 10.84, 10.85] 4plt.plot(year,pop) 5plt.show() Scatter plot The resulting scatter plot simply plots all the individual data points; Python doesn\u0026rsquo;t connect the dots with a line. For many applications, the scatter plot is often a better choice than the line plot, so remember this scatter function well. You could also say that this is a more -honest- way of plotting your data, because you can clearly see that the plot is based on just four data points.\nplt.xscale('log') Put the x-axis on a logarithmic scale(以对数形式显示x轴)\nA correlation will become clear when you display the GDP per capita on a logarithmic scale.\nyou saw that the higher GDP usually corresponds to a higher life expectancy. In other words, there is a positive correlation. there is not a relationship between population and life expectancy of a country\n1gdp_cap = [974.5803384, 5937.029525999998, 6223.367465, 4797.231267, 12779.37964, 34435.367439999995, 36126.4927, 29796.04834, 1391.253792, 33692.60508, 1441.284873, 3822.137084, 7446.298803, 12569.85177, 9065.800825, 10680.79282, 1217.032994, 430.0706916, 1713.778686, 2042.09524, 36319.23501, 706.016537, 1704.063724, 13171.63885, 4959.114854, 7006.580419, 986.1478792, 277.5518587, 3632.557798, 9645.06142, 1544.750112, 14619.222719999998, 8948.102923, 22833.30851, 35278.41874, 2082.4815670000007, 6025.3747520000015, 6873.262326000001, 5581.180998, 5728.353514, 12154.08975, 641.3695236000002, 690.8055759, 33207.0844, 30470.0167, 13206.48452, 752.7497265, 32170.37442, 1327.60891, 27538.41188, 5186.050003, 942.6542111, 579.2317429999998, 1201.637154, 3548.3308460000007, 39724.97867, 18008.94444, 36180.78919, 2452.210407, 3540.651564, 11605.71449, 4471.061906, 40675.99635, 25523.2771, 28569.7197, 7320.8802620000015, 31656.06806, 4519.461171, 1463.249282, 1593.06548, 23348.139730000006, 47306.98978, 10461.05868, 1569.331442, 414.5073415, 12057.49928, 1044.770126, 759.3499101, 12451.6558, 1042.581557, 1803.151496, 10956.99112, 11977.57496, 3095.7722710000007, 9253.896111, 3820.17523, 823.6856205, 944.0, 4811.060429, 1091.359778, 36797.93332, 25185.00911, 2749.320965, 619.6768923999998, 2013.977305, 49357.19017, 22316.19287, 2605.94758, 9809.185636, 4172.838464, 7408.905561, 3190.481016, 15389.924680000002, 20509.64777, 19328.70901, 7670.122558, 10808.47561, 863.0884639000002, 1598.435089, 21654.83194, 1712.472136, 9786.534714, 862.5407561000002, 47143.17964, 18678.31435, 25768.25759, 926.1410683, 9269.657808, 28821.0637, 3970.095407, 2602.394995, 4513.480643, 33859.74835, 37506.41907, 4184.548089, 28718.27684, 1107.482182, 7458.396326999998, 882.9699437999999, 18008.50924, 7092.923025, 8458.276384, 1056.380121, 33203.26128, 42951.65309, 10611.46299, 11415.80569, 2441.576404, 3025.349798, 2280.769906, 1271.211593, 469.70929810000007] 2life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 3pop = [31.889923, 3.600523, 33.333216, 12.420476, 40.301927, 20.434176, 8.199783, 0.708573, 150.448339, 10.392226, 8.078314, 9.119152, 4.552198, 1.639131, 190.010647, 7.322858, 14.326203, 8.390505, 14.131858, 17.696293, 33.390141, 4.369038, 10.238807, 16.284741, 1318.683096, 44.22755, 0.71096, 64.606759, 3.80061, 4.133884, 18.013409, 4.493312, 11.416987, 10.228744, 5.46812, 0.496374, 9.319622, 13.75568, 80.264543, 6.939688, 0.551201, 4.906585, 76.511887, 5.23846, 61.083916, 1.454867, 1.688359, 82.400996, 22.873338, 10.70629, 12.572928, 9.947814, 1.472041, 8.502814, 7.483763, 6.980412, 9.956108, 0.301931, 1110.396331, 223.547, 69.45357, 27.499638, 4.109086, 6.426679, 58.147733, 2.780132, 127.467972, 6.053193, 35.610177, 23.301725, 49.04479, 2.505559, 3.921278, 2.012649, 3.193942, 6.036914, 19.167654, 13.327079, 24.821286, 12.031795, 3.270065, 1.250882, 108.700891, 2.874127, 0.684736, 33.757175, 19.951656, 47.76198, 2.05508, 28.90179, 16.570613, 4.115771, 5.675356, 12.894865, 135.031164, 4.627926, 3.204897, 169.270617, 3.242173, 6.667147, 28.674757, 91.077287, 38.518241, 10.642836, 3.942491, 0.798094, 22.276056, 8.860588, 0.199579, 27.601038, 12.267493, 10.150265, 6.144562, 4.553009, 5.447502, 2.009245, 9.118773, 43.997828, 40.448191, 20.378239, 42.292929, 1.133066, 9.031088, 7.554661, 19.314747, 23.174294, 38.13964, 65.068149, 5.701579, 1.056608, 10.276158, 71.158647, 29.170398, 60.776238, 301.139947, 3.447496, 26.084662, 85.262356, 4.018332, 22.211743, 11.746035, 12.311143] 4plt.scatter(gdp_cap, life_exp) 5plt.xscale(\u0026#39;log\u0026#39;) 6plt.show() 7plt.clf() 8plt.scatter(pop, life_exp) 9# plt.xscale(\u0026#39;log\u0026#39;) 10plt.show() 11plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  histogram The histogram is a type of visualization that\u0026rsquo;s very useful to explore your data. It can help you to get an idea about the distribution of your variables.\nbin To build a histogram for these values, you can divide the line into equal chunks, called bins.Finally, you draw a bar for each bin.\nTo see how it works, imagine 12 values between 0 and 6.Suppose you go for 3 bins, that each have a width of 2. Next, you count how many data points sit inside each bin.There\u0026rsquo;s 4 data points in the first bin,6 in the second bin,and 2 in the third bin. Size of bin The number of bins is pretty important. Too few bins will oversimplify reality and won\u0026rsquo;t show you the details. Too many bins will overcomplicate reality and won\u0026rsquo;t show the bigger picture.\nplot histogram Finally, you draw a bar for each bin.The height of the bar corresponds to the number of data points that fall in this bin.\nyou can use the hist() function to plot a histogram\nThere\u0026rsquo;s a bunch of arguments you can specify, but the first two here are the most important ones. x should be a list of values you want to build a histogram for. You can use the second argument, bins, to tell Python into how many bins the data should be divided. Based on this number, hist will automatically find appropriate boundaries for all bins, and calculate how may values are in each one. If you don\u0026rsquo;t specify the bins argument, it will by 10 by default.\n1life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 2plt.hist(life_exp,5) 3plt.show() 4plt.clf() 5plt.hist(life_exp,20) 6plt.show() 7plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  line-plot VS scatter-plot VS histogram line-plot When you have a time scale along the horizontal axis, the line plot is your friend.\nscatter-plot But in many other cases, when you\u0026rsquo;re trying to assess if there\u0026rsquo;s a correlation between two variables, for example, the scatter plot is the better choice.\nscatter-plot It can help you to get an idea about the distribution of your variables.And it was very easy to make a comparison.\n1life_exp1950 = [28.8, 55.23, 43.08, 30.02, 62.48, 69.12, 66.8, 50.94, 37.48, 68.0, 38.22, 40.41, 53.82, 47.62, 50.92, 59.6, 31.98, 39.03, 39.42, 38.52, 68.75, 35.46, 38.09, 54.74, 44.0, 50.64, 40.72, 39.14, 42.11, 57.21, 40.48, 61.21, 59.42, 66.87, 70.78, 34.81, 45.93, 48.36, 41.89, 45.26, 34.48, 35.93, 34.08, 66.55, 67.41, 37.0, 30.0, 67.5, 43.15, 65.86, 42.02, 33.61, 32.5, 37.58, 41.91, 60.96, 64.03, 72.49, 37.37, 37.47, 44.87, 45.32, 66.91, 65.39, 65.94, 58.53, 63.03, 43.16, 42.27, 50.06, 47.45, 55.56, 55.93, 42.14, 38.48, 42.72, 36.68, 36.26, 48.46, 33.68, 40.54, 50.99, 50.79, 42.24, 59.16, 42.87, 31.29, 36.32, 41.72, 36.16, 72.13, 69.39, 42.31, 37.44, 36.32, 72.67, 37.58, 43.44, 55.19, 62.65, 43.9, 47.75, 61.31, 59.82, 64.28, 52.72, 61.05, 40.0, 46.47, 39.88, 37.28, 58.0, 30.33, 60.4, 64.36, 65.57, 32.98, 45.01, 64.94, 57.59, 38.64, 41.41, 71.86, 69.62, 45.88, 58.5, 41.22, 50.85, 38.6, 59.1, 44.6, 43.58, 39.98, 69.18, 68.44, 66.07, 55.09, 40.41, 43.16, 32.55, 42.04, 48.45] 2life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 3 4plt.hist(life_exp,15) 5plt.show() 6plt.clf() 7plt.hist(life_exp1950,15) 8plt.show() 9plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Customization Creating a plot is one thing. Making the correct plot, that makes the message very clear \u0026ndash; that\u0026rsquo;s the real challenge.\nData visualization For each visualization, you have many options. First of all, there are the different plot types. And for each plot, you can do an infinite number of customizations. You can change colors, shapes, labels, axes, and so on. The choice depends on: one, the data, and two, the story you want to tell with this data.\nAxis labels First, it should be clearer which data we are displaying, especially to people who are seeing the graph for the first time. And second, the plot really needs to draw the attention to the population explosion.\nThe first thing you always need to do is label your axes. Let\u0026rsquo;s do this by adding the xlabel() and ylabel() functions. As inputs, we pass strings that should be placed alongside the axes. Make sure to call these functions before calling the show function, otherwise your customizations will not be displayed.\nTitle We\u0026rsquo;re also going to add a title to our plot, with the title() function. We pass the actual title, \u0026lsquo;World Population Projections\u0026rsquo;, as an argument.\n1import matplotlib.pyplot as plt 2year = [1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100] 3pop = [2.53, 2.57, 2.62, 2.67, 2.71, 2.76, 2.81, 2.86, 2.92, 2.97, 3.03, 3.08, 3.14, 3.2, 3.26, 3.33, 3.4, 3.47, 3.54, 3.62, 3.69, 3.77, 3.84, 3.92, 4.0, 4.07, 4.15, 4.22, 4.3, 4.37, 4.45, 4.53, 4.61, 4.69, 4.78, 4.86, 4.95, 5.05, 5.14, 5.23, 5.32, 5.41, 5.49, 5.58, 5.66, 5.74, 5.82, 5.9, 5.98, 6.05, 6.13, 6.2, 6.28, 6.36, 6.44, 6.51, 6.59, 6.67, 6.75, 6.83, 6.92, 7.0, 7.08, 7.16, 7.24, 7.32, 7.4, 7.48, 7.56, 7.64, 7.72, 7.79, 7.87, 7.94, 8.01, 8.08, 8.15, 8.22, 8.29, 8.36, 8.42, 8.49, 8.56, 8.62, 8.68, 8.74, 8.8, 8.86, 8.92, 8.98, 9.04, 9.09, 9.15, 9.2, 9.26, 9.31, 9.36, 9.41, 9.46, 9.5, 9.55, 9.6, 9.64, 9.68, 9.73, 9.77, 9.81, 9.85, 9.88, 9.92, 9.96, 9.99, 10.03, 10.06, 10.09, 10.13, 10.16, 10.19, 10.22, 10.25, 10.28, 10.31, 10.33, 10.36, 10.38, 10.41, 10.43, 10.46, 10.48, 10.5, 10.52, 10.55, 10.57, 10.59, 10.61, 10.63, 10.65, 10.66, 10.68, 10.7, 10.72, 10.73, 10.75, 10.77, 10.78, 10.79, 10.81, 10.82, 10.83, 10.84, 10.85] 4plt.plot(year,pop) 5plt.xlabel(\u0026#34;Year\u0026#34;) 6plt.ylabel(\u0026#34;Population\u0026#34;) 7plt.title(\u0026#34;World Population Prediction\u0026#34;) 8plt.show() So, using xlabel, ylabel and title, we can give the reader more information about the data on the plot\nTicks To put the population growth in perspective, I want to have the y-axis start from zero.\nYou can do this with the yticks() function. The first input is a list, in this example with the numbers zero up to ten, with intervals of 2.(从0到10间隔为2的数字)If we run this, the plot will change: the curve shifts up.\n1plt.plot(year,pop) 2plt.xlabel(\u0026#34;Year\u0026#34;) 3plt.ylabel(\u0026#34;Population\u0026#34;) 4plt.title(\u0026#34;World Population Prediction\u0026#34;) 5plt.yticks([0, 2, 4, 6, 8, 10]) 6plt.show() names of the ticks Next, to make it clear we\u0026rsquo;re talking about billions, we can add a second argument to the yticks function, which is a list with the display names of the ticks. This list should have the same length as the first list. The tick 0 gets the name 0, the tick 2 gets the name 2B, the tick 4 gets the name 4B and so on. By the way, B stands for Billions here. If we run this version of the script,the labels will change accordingly.\n1plt.plot(year,pop) 2plt.xlabel(\u0026#34;Year\u0026#34;) 3plt.ylabel(\u0026#34;Population\u0026#34;) 4plt.title(\u0026#34;World Population Prediction\u0026#34;) 5plt.yticks([0, 2, 4, 6, 8, 10],\\ 6 [\u0026#39;0\u0026#39;, \u0026#39;2B\u0026#39;, \u0026#39;4B\u0026#39;, \u0026#39;6B\u0026#39;, \u0026#39;8B\u0026#39;, \u0026#39;10B\u0026#39;]) 7plt.show() Size of the scatter plot Right now, the scatter plot is just a cloud of blue dots, indistinguishable from each other. Let\u0026rsquo;s change this. Wouldn\u0026rsquo;t it be nice if the size of the dots corresponds to the population?\nYou can see that this list is added to the scatter() method, as the argument s, for size.\n1gdp_cap = [974.5803384, 5937.029525999998, 6223.367465, 4797.231267, 12779.37964, 34435.367439999995, 36126.4927, 29796.04834, 1391.253792, 33692.60508, 1441.284873, 3822.137084, 7446.298803, 12569.85177, 9065.800825, 10680.79282, 1217.032994, 430.0706916, 1713.778686, 2042.09524, 36319.23501, 706.016537, 1704.063724, 13171.63885, 4959.114854, 7006.580419, 986.1478792, 277.5518587, 3632.557798, 9645.06142, 1544.750112, 14619.222719999998, 8948.102923, 22833.30851, 35278.41874, 2082.4815670000007, 6025.3747520000015, 6873.262326000001, 5581.180998, 5728.353514, 12154.08975, 641.3695236000002, 690.8055759, 33207.0844, 30470.0167, 13206.48452, 752.7497265, 32170.37442, 1327.60891, 27538.41188, 5186.050003, 942.6542111, 579.2317429999998, 1201.637154, 3548.3308460000007, 39724.97867, 18008.94444, 36180.78919, 2452.210407, 3540.651564, 11605.71449, 4471.061906, 40675.99635, 25523.2771, 28569.7197, 7320.8802620000015, 31656.06806, 4519.461171, 1463.249282, 1593.06548, 23348.139730000006, 47306.98978, 10461.05868, 1569.331442, 414.5073415, 12057.49928, 1044.770126, 759.3499101, 12451.6558, 1042.581557, 1803.151496, 10956.99112, 11977.57496, 3095.7722710000007, 9253.896111, 3820.17523, 823.6856205, 944.0, 4811.060429, 1091.359778, 36797.93332, 25185.00911, 2749.320965, 619.6768923999998, 2013.977305, 49357.19017, 22316.19287, 2605.94758, 9809.185636, 4172.838464, 7408.905561, 3190.481016, 15389.924680000002, 20509.64777, 19328.70901, 7670.122558, 10808.47561, 863.0884639000002, 1598.435089, 21654.83194, 1712.472136, 9786.534714, 862.5407561000002, 47143.17964, 18678.31435, 25768.25759, 926.1410683, 9269.657808, 28821.0637, 3970.095407, 2602.394995, 4513.480643, 33859.74835, 37506.41907, 4184.548089, 28718.27684, 1107.482182, 7458.396326999998, 882.9699437999999, 18008.50924, 7092.923025, 8458.276384, 1056.380121, 33203.26128, 42951.65309, 10611.46299, 11415.80569, 2441.576404, 3025.349798, 2280.769906, 1271.211593, 469.70929810000007] 2life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 3pop = [31.889923, 3.600523, 33.333216, 12.420476, 40.301927, 20.434176, 8.199783, 0.708573, 150.448339, 10.392226, 8.078314, 9.119152, 4.552198, 1.639131, 190.010647, 7.322858, 14.326203, 8.390505, 14.131858, 17.696293, 33.390141, 4.369038, 10.238807, 16.284741, 1318.683096, 44.22755, 0.71096, 64.606759, 3.80061, 4.133884, 18.013409, 4.493312, 11.416987, 10.228744, 5.46812, 0.496374, 9.319622, 13.75568, 80.264543, 6.939688, 0.551201, 4.906585, 76.511887, 5.23846, 61.083916, 1.454867, 1.688359, 82.400996, 22.873338, 10.70629, 12.572928, 9.947814, 1.472041, 8.502814, 7.483763, 6.980412, 9.956108, 0.301931, 1110.396331, 223.547, 69.45357, 27.499638, 4.109086, 6.426679, 58.147733, 2.780132, 127.467972, 6.053193, 35.610177, 23.301725, 49.04479, 2.505559, 3.921278, 2.012649, 3.193942, 6.036914, 19.167654, 13.327079, 24.821286, 12.031795, 3.270065, 1.250882, 108.700891, 2.874127, 0.684736, 33.757175, 19.951656, 47.76198, 2.05508, 28.90179, 16.570613, 4.115771, 5.675356, 12.894865, 135.031164, 4.627926, 3.204897, 169.270617, 3.242173, 6.667147, 28.674757, 91.077287, 38.518241, 10.642836, 3.942491, 0.798094, 22.276056, 8.860588, 0.199579, 27.601038, 12.267493, 10.150265, 6.144562, 4.553009, 5.447502, 2.009245, 9.118773, 43.997828, 40.448191, 20.378239, 42.292929, 1.133066, 9.031088, 7.554661, 19.314747, 23.174294, 38.13964, 65.068149, 5.701579, 1.056608, 10.276158, 71.158647, 29.170398, 60.776238, 301.139947, 3.447496, 26.084662, 85.262356, 4.018332, 22.211743, 11.746035, 12.311143] 4plt.scatter(gdp_cap,life_exp,s = pop) 5plt.xscale(\u0026#39;log\u0026#39;) 6plt.xlabel(\u0026#39;GDP per Capita [in USD]\u0026#39;) 7plt.ylabel(\u0026#39;Life Expectancy [in years]\u0026#39;) 8plt.title(\u0026#39;World Development in 2007\u0026#39;) 9plt.xticks([1000, 10000, 100000],[\u0026#39;1k\u0026#39;, \u0026#39;10k\u0026#39;, \u0026#39;100k\u0026#39;]) 10plt.show() 11plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Colors The next step is making the plot more colorful! To do this, a list col has been created for you. It\u0026rsquo;s a list with a color for each corresponding country, depending on the continent the country is part of.\nHow did we make the list col you ask? The Gapminder data contains a list continent with the continent each country belongs to. A dictionary is constructed that maps continents onto colors:\n1dict = { 2 \u0026#39;Asia\u0026#39;:\u0026#39;red\u0026#39;, 3 \u0026#39;Europe\u0026#39;:\u0026#39;green\u0026#39;, 4 \u0026#39;Africa\u0026#39;:\u0026#39;blue\u0026#39;, 5 \u0026#39;Americas\u0026#39;:\u0026#39;yellow\u0026#39;, 6 \u0026#39;Oceania\u0026#39;:\u0026#39;black\u0026#39; 7} Opacity of plot Change the opacity of the bubbles by setting the alpha argument\nAlpha can be set from zero to one, where zero is totally transparent, and one is not at all transparent.\nText text() function can add the words into the plot.\ngridiness(网格) grid() function can draw the gridiness into the plot.\n1col = [\u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;black\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;black\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;] 2plt.figure(dpi=300) 3plt.scatter(gdp_cap,life_exp,s = pop,c = col,alpha = 0.8) 4plt.xscale(\u0026#39;log\u0026#39;) 5plt.xlabel(\u0026#39;GDP per Capita [in USD]\u0026#39;) 6plt.ylabel(\u0026#39;Life Expectancy [in years]\u0026#39;) 7plt.title(\u0026#39;World Development in 2007\u0026#39;) 8plt.xticks([1000, 10000, 100000],[\u0026#39;1k\u0026#39;, \u0026#39;10k\u0026#39;, \u0026#39;100k\u0026#39;]) 9plt.text(1550, 71, \u0026#39;India\u0026#39;) 10plt.text(5700, 80, \u0026#39;China\u0026#39;) 11plt.grid(True) 12plt.show() Pandas Pandas is a high level data manipulation tool developed by Wes McKinney, built on the Numpy and matplotlib package,providing high-performance, easy-to-use data structures and data analysis tools for Python.\nCompared to Numpy, it\u0026rsquo;s more high level, making it very interesting for data scientists all over the world.\nIn pandas, we store the tabular data like the brics table here in an object called a DataFrame.\nMotivation As a data scientist, you\u0026rsquo;ll often be working with tons of data. The form of this data can vary greatly, but pretty often, you can boil it down to a tabular structure, that is, in the form of a table like in a spreadsheet.\n2D numpy array? Well, it\u0026rsquo;s an option, but not necessarily the best one. In the two examples we covered, there are different data types and Numpy arrays are not great at handling these.\nnumpy数组为了加速运算只允许存储一种数据类型，然而大多数情况下我们的数据集包含多种不同的数据类型\nTabular dataset examples This data can come in the following form:\nEvery row is a measurement, or an observation, and for each observation, there are different variables.\nDataFrame The DataFrame is one of Pandas' most important data structures. It\u0026rsquo;s basically a way to store tabular data where you can label the rows and the columns.\nAlso notice that each row and column has a unique label(行和列都有唯一的标签)\nNotice that the values in the different columns have different types.(不同列的值可以是不同的数据类型)\nHow to build DataFrame DataFrame from Dictionary The keys are the column labels, and the values are the corresponding columns, in list form.\nAfter importing the pandas package as pd, you can create a DataFrame from the dictionary using pd.DataFrame().\nPandas assigned some automatic row labels,to specify them manually, you can set the index attribute to a list with the correct labels.(手动指定列标签：将DataFrame的index属性设置为带有标签的List)\n1import pandas as pd 2dict = { \u0026#34;country\u0026#34;:[\u0026#34;Brazil\u0026#34;, \u0026#34;Russia\u0026#34;, \u0026#34;India\u0026#34;, \u0026#34;China\u0026#34;, \u0026#34;South Africa\u0026#34;],\\ 3 \u0026#34;capital\u0026#34;:[\u0026#34;Brasilia\u0026#34;, \u0026#34;Moscow\u0026#34;, \u0026#34;New Delhi\u0026#34;, \u0026#34;Beijing\u0026#34;, \u0026#34;Pretoria\u0026#34;],\\ 4 \u0026#34;area\u0026#34;:[8.516, 17.10, 3.286, 9.597, 1.221],\\ 5 \u0026#34;population\u0026#34;:[200.4, 143.5, 1252, 1357, 52.98] } 6brics = pd.DataFrame(dict) 7print(brics) 8brics.index = [\u0026#39;BR\u0026#39;,\u0026#39;RU\u0026#39;,\u0026#39;IN\u0026#39;,\u0026#39;CH\u0026#39;,\u0026#39;SA\u0026#39;] 9print(brics)  country capital area population 0 Brazil Brasilia 8.516 200.40 1 Russia Moscow 17.100 143.50 2 India New Delhi 3.286 1252.00 3 China Beijing 9.597 1357.00 4 South Africa Pretoria 1.221 52.98 country capital area population BR Brazil Brasilia 8.516 200.40 RU Russia Moscow 17.100 143.50 IN India New Delhi 3.286 1252.00 CH China Beijing 9.597 1357.00 SA South Africa Pretoria 1.221 52.98  DataFrame from external file Using a dictionary approach is fine, but what if you\u0026rsquo;re working with tons of data, which is typically the case as a data scientist?\nIn those cases, the data is typically available as files with a regular structure. One of those file types is the CSV file, which is short for \u0026ldquo;comma-separated values\u0026rdquo;\nInstead, you import data from an external file that contains all this data.\nCSV File CSV is short for comma separated values.(CSV是以逗号分隔数组的缩写)\nimport from .CSV file we can do this by using Pandas read_csv() function,You pass the path to the csv file as an argument.\nthere\u0026rsquo;s still something wrong. The row labels are seen as a column in their own right. To solve this, we\u0026rsquo;ll have to tell the read_csv function that the first column contains the row indexes. You do this by setting the index_col argument inside pd.read_csv.\nThis time it makes sure that the rows and columns are given appropriate labels. This is important to make accessing columns, rows and single elements in your DataFrame easy.\nThe read_csv function features many more arguments that allow you to customize your data import, make sure to check out its documentation\n1import pandas as pd 2brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;) 3print(brics) 4brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;,index_col = 0) 5print(brics) 6  Unnamed: 0 country capital area population 0 BR Brazil Brasilia 8.516 200.40 1 RU Russia Moscow 17.100 143.50 2 IN India New Delhi 3.286 1252.00 3 CH China Beijing 9.597 1357.00 4 SA South Africa Pretoria 1.221 52.98 country capital area population BR Brazil Brasilia 8.516 200.40 RU Russia Moscow 17.100 143.50 IN India New Delhi 3.286 1252.00 CH China Beijing 9.597 1357.00 SA South Africa Pretoria 1.221 52.98  Index and select data There are numerous ways in which you can index and select data from DataFrames.\nColumn Access [ ] Suppose that you only want to select a column from DataFrame.\nyou type the column label inside square brackets.\nBut there\u0026rsquo;s something strange here. The last line says Name: country, dtype: object.\nSo we\u0026rsquo;re dealing with a Pandas Series here\nSeries type of Pandas In a simplified sense, you can think of the Series as a 1-dimensional array that can be labeled, just like the DataFrame. Otherwise put, if you paste together a bunch of Series, you can create a DataFrame.\n1country = brics[\u0026#34;country\u0026#34;] 2print(country) 3print(type(country)) BR Brazil RU Russia IN India CH China SA South Africa Name: country, dtype: object \u0026lt;class 'pandas.core.series.Series'\u0026gt;  Selete data but keep the data in a DataFrame you\u0026rsquo;ll need double square brackets.\nIf you look at it from a different angle, you\u0026rsquo;re actually putting a list with column labels inside another set of square bracket\n1country = brics[[\u0026#34;country\u0026#34;]] 2print(country) 3print(type(country))  country BR Brazil RU Russia IN India CH China SA South Africa \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; country capital BR Brazil Brasilia RU Russia Moscow IN India New Delhi CH China Beijing SA South Africa Pretoria \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  1capital = brics[[\u0026#34;country\u0026#34;,\u0026#34;capital\u0026#34;]] 2print(capital) 3print(type(capital))  country capital BR Brazil Brasilia RU Russia Moscow IN India New Delhi CH China Beijing SA South Africa Pretoria \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  Row Access [ ] The way to do it is by specifying a slice.To get the second, third and fourth rows of brics, we use the slice 1 colon 4. Remember that the end of the slice is exclusive and that the index starts at zero.\n1print(brics[1:4]) 2print(type(brics[1:4]))  country capital area population RU Russia Moscow 17.100 143.5 IN India New Delhi 3.286 1252.0 CH China Beijing 9.597 1357.0 \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  Adanced methods These square brackets work, but it only offers limited functionality. Ideally, we\u0026rsquo;d want something similar to 2D Numpy arrays. There, you also used square brackets, the index or slice before the comma referred to the rows, the index or slice after the comma referred to the columns. If we want to do a similar thing with Pandas, we have to extend our toolbox with the loc() and iloc() functions.\nloc(advanced method) loc is label-based, which means that you have to specify rows and columns based on their row and column labels.\nYou put the label of the row of interest in square brackets after loc.we get a Pandas Series, containing all the row\u0026rsquo;s information, rather inconveniently shown on different lines.(series信息单独在一列上显示，很不方便)\nTo get a data frame, we have to put list which include the labels inside another pair of brackets.\nWe can also select multiple rows at the same time.This will do the trick; simply add some more row labels to the list.\n1CH = brics.loc[\u0026#39;CH\u0026#39;] 2print(CH) 3print(type(CH)) country China capital Beijing area 9.597 population 1357 Name: CH, dtype: object \u0026lt;class 'pandas.core.series.Series'\u0026gt;  1DF_CH = brics.loc[[\u0026#39;CH\u0026#39;]] 2print(DF_CH) 3print(type(DF_CH))  country capital area population CH China Beijing 9.597 1357.0 \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  1print(brics.loc[[\u0026#39;CH\u0026#39;,\u0026#39;IN\u0026#39;]])  country capital area population CH China Beijing 9.597 1357.0 IN India New Delhi 3.286 1252.0  This was only selecting entire rows, that\u0026rsquo;s something you could also do with the basic square brackets. The difference here is that you can extend your selection with a comma and a specification of the columns of interest.\n(用这种在方括号中输入list的方法，我们还可以在列标签的list后，加上逗号，和行标签的list。这样就不用选取一整行)\nWe add a comma, and a list of column labels we want to keep. The intersection gets returned.\nOf course, you can also use loc to select all rows but only a specific number of columns.\nSimply replace the first list that specifies the row labels with a colon, a slice going from beginning to end. This time, the intersection spans all rows\n1print(brics.loc[[\u0026#39;CH\u0026#39;,\u0026#39;IN\u0026#39;],[\u0026#39;country\u0026#39;,\u0026#39;capital\u0026#39;]])  country capital CH China Beijing IN India New Delhi  1print(brics.loc[:,[\u0026#39;country\u0026#39;,\u0026#39;capital\u0026#39;]])  country capital BR Brazil Brasilia RU Russia Moscow IN India New Delhi CH China Beijing SA South Africa Pretoria  iloc(advanced method) iloc is integer index based, so you have to specify rows and columns by their integer index\nloc and iloc are pretty similar, the only difference is how you refer to columns and rows.you can keep all rows or columns in a similar fashion.\n1print(brics.iloc[3]) country China capital Beijing area 9.597 population 1357 Name: CH, dtype: object  1print(brics.iloc[[2,3]])  country capital area population IN India New Delhi 3.286 1252.0 CH China Beijing 9.597 1357.0  1print(brics.iloc[[2,3],[0,1]])  country capital IN India New Delhi CH China Beijing  square bracket VS loc() or iloc() square bracket simple square brackets work fine if you want to get columns; to get rows, you can use slicing.\n只想整行或者整列筛选，可以使用简单的方括号\nloc() or iloc() The loc function is more versatile: you can select rows, columns, but also rows and columns at the same time. When you use loc, subsetting becomes remarkable similar to how you subsetted 2D Numpy arrays.\n即想进行行筛选，又想进行列筛选，可以选择loc()\nFiltering pandas DataFrames illustration Suppose you now want to keep the countries, so the observations in this case, for which the area is greater than 8 million square kilometers.\nThere are three steps to this:\nFirst of all, we want to get the area column from brics.\nNext, we perform the comparison on this column and store its result.\nFinally, we should use this result to do the appropriate selection on the DataFrame.\nGet column There are many different ways to do this. What\u0026rsquo;s important here, is that we ideally get a Pandas Series, not a Pandas DataFrame.(必须用Series数据类型)\nCompare Next, we actually perform the comparison.we simply use comparsion operator in this.Now we get a Series containing booleans or Boolean Series.\nsubset DataFrame The final step is using this boolean Series to subset the Pandas DataFrame.you put Boolen Series inside square brackets.so we can get a DataFrame that conform the condition.\n1print(brics[brics[\u0026#39;area\u0026#39;]\u0026gt;8])  country capital area population BR Brazil Brasilia 8.516 200.4 RU Russia Moscow 17.100 143.5 CH China Beijing 9.597 1357.0  Boolean operators Because Pandas is built on Numpy, you can also use that function here.\n1import numpy as np 2print(brics[np.logical_and(brics[\u0026#39;area\u0026#39;]\u0026gt;8,brics[\u0026#39;area\u0026#39;]\u0026lt;10)])  country capital area population BR Brazil Brasilia 8.516 200.4 CH China Beijing 9.597 1357.0  Loop Data Structures 1D numpy array It is just same as list.\n2D numpy array To get every element of an array, you can use a Numpy function called nditer().\n1import numpy as np 2np_height = np.array([1.73, 1.68, 1.71, 1.89, 1.79]) 3np_weight = np.array([65.4, 59.2, 63.6, 88.4, 68.7]) 4meas = np.array([np_height, np_weight]) 5for x in np.nditer(meas): 6 print(x) 1.73 1.68 1.71 1.89 1.79 65.4 59.2 63.6 88.4 68.7  Loop for Pandas DataFrame Loop over row labels a basic for loop simply got the column names.\n1brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;,index_col=0) 2for x in brics : 3 print(x) country capital area population  Loop over row In Pandas,if you want to iterate over each row,you have to mention explicitly.\nYou do this by calling the iterrows() method\nThe iterrows() method looks at the data frame, and on each iteration generates two pieces of data: the label of the row and then the actual data in the row as a Pandas Series.\n1for lab,row in brics.iterrows(): 2 print(lab) 3 print(row) BR country Brazil capital Brasilia area 8.516 population 200.4 Name: BR, dtype: object RU country Russia capital Moscow area 17.1 population 143.5 Name: RU, dtype: object IN country India capital New Delhi area 3.286 population 1252 Name: IN, dtype: object CH country China capital Beijing area 9.597 population 1357 Name: CH, dtype: object SA country South Africa capital Pretoria area 1.221 population 52.98 Name: SA, dtype: object  Add column we need to iterate over the row,so we can get both the row label and the row data.\nwe\u0026rsquo;ll have to add this new information to a new column at the appropriate location.\n1for lab,row in brics.iterrows(): 2 brics.loc[lab,\u0026#39;name_length\u0026#39;] = len(row[\u0026#39;country\u0026#39;]) 3print(brics)  country capital area population name_length BR Brazil Brasilia 8.516 200.40 6.0 RU Russia Moscow 17.100 143.50 6.0 IN India New Delhi 3.286 1252.00 5.0 CH China Beijing 9.597 1357.00 5.0 SA South Africa Pretoria 1.221 52.98 12.0  apply() You can vectorized operations with the apply function\nPrevious method was not especially efficient , because you\u0026rsquo;re creating a Series object on every iteration. For this small DataFrame that doesn\u0026rsquo;t matter, but if you\u0026rsquo;re doing funky stuff on a ginormous dataset, this loss in efficiency can become problematic.\nIf you want to add a column to a DataFrame by calling a function on another column, the iterrows() method in combination with a for loop is not the preferred way to go.\nA way better approach if you want to calculate an entire DataFrame column by applying a function on a particular column in an element-wise fashion, is apply().\nBasically, you\u0026rsquo;re selecting the column from the DataFrame, and then, on this column, you apply the len function.\nApply calls the function with each value as input and produces a new array, that you can easily store as a new column\n1brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;,index_col=0) 2brics[\u0026#39;name_length\u0026#39;] = brics[\u0026#39;country\u0026#39;].apply(len) 3brics .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  1i=73 2print(id(i)) 3i+=2 4print(id(i)) 4483145248 4483145312  ","date":"Sep 4, 2021","img":"","permalink":"/en/posts/tutorialnotebook/","series":null,"tags":null,"title":"TutorialNotebook"},{"categories":null,"content":"Logistic Regression In this part of the exercise, you will build a logistic regression model to predict whether a student gets admitted into a university.\nSuppose that you are the administrator of a university department and you want to determine each applicant’s chance of admission based on their results on two exams. You have historical data from previous applicants that you can use as a training set for logistic regression. For each training example, you have the applicant’s scores on two exams and the admissions decision. Your task is to build a classification model that estimates an applicant’s probability of admission based the scores from those two exams.\nVisualizing the data 1import numpy as np 2import pandas as pd 3import matplotlib.pyplot as plt 1df = pd.read_csv(\u0026#34;ex2data1.txt\u0026#34;,header=None,names=[\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;,\u0026#34;Admitted\u0026#34;]) 2df.head() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  1positive_df = df[df[\u0026#34;Admitted\u0026#34;] == 1] 2negative_df = df[df[\u0026#34;Admitted\u0026#34;] == 0] 3plt.clf() 4plt.figure(dpi=300,figsize=(10,8)) 5plt.scatter(positive_df[\u0026#34;Exam1\u0026#34;],positive_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;+\u0026#39;,c=\u0026#39;black\u0026#39;,s=50,label=\u0026#34;Admitted\u0026#34;) 6plt.scatter(negative_df[\u0026#34;Exam1\u0026#34;],negative_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;o\u0026#39;,c=\u0026#39;y\u0026#39;,s=50,label=\u0026#34;Not Admitted\u0026#34;) 7plt.xlabel(\u0026#34;Exam 1 Score\u0026#34;) 8plt.ylabel(\u0026#34;Exam 2 Score\u0026#34;) 9plt.title(\u0026#34;Scatter plot of Training data\u0026#34;) 10plt.legend() \u0026lt;matplotlib.legend.Legend at 0x7f813cb38588\u0026gt; \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Implementation 通过对比对数据是否进行归一化，可以看到梯度下降的速度的明显差距\ngradient descent without feature scaling 不进行特征缩放时：1.学习率可能需要很小，代价函数才开始收敛。2.最终收敛所需的迭代次数非常多（收敛慢）\n1def sigmoid(x): 2 return 1/( 1 + np.exp(-x) ) 3def cost_comput(theta,X,y): 4 theta = np.matrix(theta).T 5 first = np.multiply(y, np.log(sigmoid(X * theta))) 6 second = np.multiply((y - 1), np.log(1 - sigmoid(X * theta))) 7 return np.sum(second - first) / (len(X)) 8def gradient(theta,X,y): 9 theta = np.mat(theta).T 10 distance = sigmoid(X * theta) - y 11# print((X.T * distance ).shape) 12# return sum(np.multiply( distance,X )) / X.shape[0] 13 return (X.T * distance ).T/ X.shape[0] 14 15def logistic_regression_gradient_descent(X,y,iter_num,alpha=0.01): 16 theta = np.zeros(X.shape[1]) 17 cost = [] 18 for i in range(iter_num): 19 theta = theta - alpha * gradient(theta,X,y) 20 cost.append(cost_comput(theta,X,y)) 21 theta = np.mat(theta).T 22 return theta,cost 23 24df[\u0026#34;ones\u0026#34;]=1 25X = np.mat(df[[\u0026#34;ones\u0026#34;,\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;]]) 26y = np.mat(df[\u0026#34;Admitted\u0026#34;]).T 27theta = np.zeros(X.shape[1]) 28 29print(gradient(theta,X,y)) 30print(cost_comput(theta,X,y)) [[ -0.1 -12.00921659 -11.26284221]] 0.6931471805599453  1iter_num = 1000 2theta,cost = logistic_regression_gradient_descent(X,y,iter_num,0.0009) 3print(theta) 4print(theta.shape) 5print(cost[-1]) 6 7plt.clf() 8plt.figure(dpi=300,figsize=(12,8)) 9plt.plot(range(1,iter_num+1),cost) [[-0.06253015] [ 0.01085921] [ 0.00093747]] (3, 1) 0.6254658375063237 [\u0026lt;matplotlib.lines.Line2D at 0x7f80eb778438\u0026gt;] \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  plot decision boundary 1x = np.linspace(df.Exam1.min(), df.Exam1.max(), X.shape[0]) 2f = ( theta[0,0]+ (x*theta[1,0]) ) / -theta[2,0] 3plt.clf() 4plt.figure(dpi=300,figsize=(10,8)) 5plt.scatter(positive_df[\u0026#34;Exam1\u0026#34;],positive_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;+\u0026#39;,c=\u0026#39;black\u0026#39;,s=50,label=\u0026#34;Admitted\u0026#34;) 6plt.scatter(negative_df[\u0026#34;Exam1\u0026#34;],negative_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;o\u0026#39;,c=\u0026#39;y\u0026#39;,s=50,label=\u0026#34;Not Admitted\u0026#34;) 7plt.xlabel(\u0026#34;Exam 1 Score\u0026#34;) 8plt.ylabel(\u0026#34;Exam 2 Score\u0026#34;) 9plt.title(\u0026#34;Scatter plot of Training data\u0026#34;) 10plt.legend() 11# print(f) 12plt.plot(x,f,\u0026#39;r\u0026#39;,label=\u0026#39;Prediction\u0026#39;) [\u0026lt;matplotlib.lines.Line2D at 0x7f80ec43c0b8\u0026gt;] \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  implementation with scipy 1import scipy.optimize as opt 2 3X = np.mat(df[[\u0026#34;ones\u0026#34;,\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;]]) 4y = np.mat(df[\u0026#34;Admitted\u0026#34;]).T 5theta = np.zeros(X.shape[1]) 6 7# opt.fmin_tnc会把变量x0当作np.array处理，所以在写函数时要做相应处理 8result = opt.fmin_tnc(func=cost_comput,x0=theta,fprime=gradient,args=(X,y)) 9print(result) 10theta = result[0] 11print(cost_comput(theta,X,y)) 12theta = np.mat(result[0]).T 13 14 15x = np.linspace(df.Exam1.min(), df.Exam1.max(), X.shape[0]) 16f = ( theta[0,0]+ (x*theta[1,0]) ) / -theta[2,0] 17plt.clf() 18plt.figure(dpi=300,figsize=(10,8)) 19plt.scatter(positive_df[\u0026#34;Exam1\u0026#34;],positive_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;+\u0026#39;,c=\u0026#39;black\u0026#39;,s=50,label=\u0026#34;Admitted\u0026#34;) 20plt.scatter(negative_df[\u0026#34;Exam1\u0026#34;],negative_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;o\u0026#39;,c=\u0026#39;y\u0026#39;,s=50,label=\u0026#34;Not Admitted\u0026#34;) 21plt.xlabel(\u0026#34;Exam 1 Score\u0026#34;) 22plt.ylabel(\u0026#34;Exam 2 Score\u0026#34;) 23plt.title(\u0026#34;Scatter plot of Training data\u0026#34;) 24plt.plot(x,f,\u0026#39;r\u0026#39;,label=\u0026#39;Prediction\u0026#39;) 25plt.legend() 26# print(f) 27 (array([-25.16131854, 0.20623159, 0.20147149]), 36, 0) 0.20349770158947492 \u0026lt;matplotlib.legend.Legend at 0x7f80ebb1cbe0\u0026gt; \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  gradient descent with feature scaling 进行特征缩放后：1.代价函数可以在学习率较大的情况下开始收敛。2.最终收敛所需的迭代次数非常少（收敛快）\n关于归一化 1.归一化是一种线性变换，它不会改变数据集的很多性质\n2.使用训练集的数据进行归一化，即使用训练集中均值和标准差进行归一化，称为归一化机制\n3.进行预测时，数据必须经过训练集归一化机制处理，如进行模型精度评估时，测试集数据必须归一化\n1df = pd.read_csv(\u0026#34;ex2data1.txt\u0026#34;,header=None,names=[\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;,\u0026#34;Admitted\u0026#34;]) 2X = df[[\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;]] 3X = ( X-X.mean() ) / X.std() 4X.insert(0,\u0026#34;ones\u0026#34;,1) 5X = np.mat(X) 6y = np.mat(df[\u0026#34;Admitted\u0026#34;]).T 7 8iter_num = 100 9alpha = 10 10theta,cost = logistic_regression_gradient_descent(X,y,iter_num,alpha) 11plt.clf() 12plt.figure(dpi=300,figsize=(12,8)) 13plt.plot(range(1,iter_num+1),cost) 14print(cost[-1]) 0.20349773676821648 \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  特征缩放下的决策边界 必须在统一的归一化机制下画图\n1# X = np.array(X) 2# print(X[:,1:3]) 3df_X = pd.DataFrame(X[:,1:3],columns=[\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;]) 4positive_df = df_X[y == 1] 5negative_df = df_X[y == 0] 6x = np.linspace(df_X.Exam1.min(), df_X.Exam1.max(), df_X.shape[0]) 7f = ( theta[0,0]+ (x*theta[1,0]) ) / -theta[2,0] 8plt.clf() 9plt.figure(dpi=300,figsize=(10,8)) 10plt.scatter(positive_df[\u0026#34;Exam1\u0026#34;],positive_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;+\u0026#39;,c=\u0026#39;black\u0026#39;,s=50,label=\u0026#34;Admitted\u0026#34;) 11plt.scatter(negative_df[\u0026#34;Exam1\u0026#34;],negative_df[\u0026#34;Exam2\u0026#34;],marker=\u0026#39;o\u0026#39;,c=\u0026#39;y\u0026#39;,s=50,label=\u0026#34;Not Admitted\u0026#34;) 12plt.xlabel(\u0026#34;Exam 1 Score\u0026#34;) 13plt.ylabel(\u0026#34;Exam 2 Score\u0026#34;) 14plt.title(\u0026#34;Scatter plot of Training data\u0026#34;) 15plt.legend() 16# print(f) 17plt.plot(x,f,\u0026#39;r\u0026#39;,label=\u0026#39;Prediction\u0026#39;) [\u0026lt;matplotlib.lines.Line2D at 0x7f813ce04710\u0026gt;] \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  特征缩放下在原数据尺度下的决策边界 1df_data = pd.read_csv(\u0026#34;ex2data1.txt\u0026#34;,header=None,names=[\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;,\u0026#34;Admitted\u0026#34;]) 2 3df_X = df_data[[\u0026#34;Exam1\u0026#34;,\u0026#34;Exam2\u0026#34;]] 4df_y = df_data[\u0026#34;Admitted\u0026#34;] 5df_norm_X = ( df_X-df_X.mean() )/ df_X.std() 6df_norm_X.insert(0,\u0026#34;Ones\u0026#34;,1) 7mat_norm_X = np.mat(df_norm_X) 8mat_y = np.mat(df_y).T 9iter_num = 100 10alpha = 10 11theta,cost = logistic_regression_gradient_descent(mat_norm_X,mat_y,iter_num,alpha) 12print(cost[-1]) 13 14 15plt.clf() 16plt.figure(dpi=300,figsize=(12,8)) 17plt.plot(range(1,iter_num+1),cost) 0.20349773676821648 [\u0026lt;matplotlib.lines.Line2D at 0x7f80dfd587f0\u0026gt;] \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1x = np.linspace(df_norm_X[\u0026#34;Exam1\u0026#34;].min(),df_norm_X[\u0026#34;Exam1\u0026#34;].max(),len(df_norm_X[\u0026#34;Exam1\u0026#34;])) 2f = (theta[0,0] + theta[1,0]*x) / -theta[2,0] 3x = x * df_X[\u0026#34;Exam1\u0026#34;].std() + df_X[\u0026#34;Exam1\u0026#34;].mean() 4f = f * df_X[\u0026#34;Exam2\u0026#34;].std() + df_X[\u0026#34;Exam2\u0026#34;].mean() 5positive_X = df_X[df_y==1] 6negative_X = df_X[df_y==0] 7plt.clf() 8plt.figure(dpi=300,figsize=(10,8)) 9plt.scatter(positive_X[\u0026#34;Exam1\u0026#34;],positive_X[\u0026#34;Exam2\u0026#34;],marker=\u0026#34;+\u0026#34;,s=50,c=\u0026#39;black\u0026#39;,label=\u0026#34;Admitted\u0026#34;) 10plt.scatter(negative_X[\u0026#34;Exam1\u0026#34;],negative_X[\u0026#34;Exam2\u0026#34;],marker=\u0026#34;o\u0026#34;,s=50,c=\u0026#39;y\u0026#39;,label=\u0026#34;Not Admitted\u0026#34;) 11plt.plot(x,f,label=\u0026#34;Decision Boundary\u0026#34;,c=\u0026#39;r\u0026#39;) 12plt.legend() \u0026lt;matplotlib.legend.Legend at 0x7f80bb5afa90\u0026gt; \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Prediction/Evaluating logistic regression After learning the parameters, you can use the model to predict whether a particular student will be admitted. For a student with an Exam 1 score of 45 and an Exam 2 score of 85, you should expect to see an admission probability of 0.776.\n1def prediction(exam1,exam2,normalization=False): 2 if normalization: 3 theta_X = (exam1-df_X[\u0026#34;Exam1\u0026#34;].mean()) / df_X[\u0026#34;Exam1\u0026#34;].std() * theta[1,0] \\ 4 + (exam2-df_X[\u0026#34;Exam2\u0026#34;].mean()) / df_X[\u0026#34;Exam2\u0026#34;].std() * theta[2,0] \\ 5 + theta[0,0] 6 else : 7 theta_X = exam1 * theta[1,0] + exam2 * theta[2,0] + theta[0,0] 8 prob = np.array(sigmoid(theta_X)) 9 predict = (prob\u0026gt;=0.5).astype(np.int) 10 return prob,predict 11 12prediction(45,85,True) (array(0.77613222), 1)  Model Accuracy Another way to evaluate the quality of the parameters we have found is to see how well the learned model predicts on our training set.\n1def model_accuracy(predict,y): 2 m = y.shape[0] 3 return ( m - int(sum((predict ^ y.T).T)) )/m 4prob,predict = prediction(df_X[\u0026#34;Exam1\u0026#34;],df_X[\u0026#34;Exam2\u0026#34;],True) 5model_accuracy(predict,mat_y) 0.89  multi-variable logistic regression In this part of the exercise, you will implement regularized logistic regression to predict whether microchips from a fabrication plant passes quality assurance (QA). During QA, each microchip goes through various tests to ensure it is functioning correctly.\nSuppose you are the product manager of the factory and you have the test results for some microchips on two different tests. From these two tests,you would like to determine whether the microchips should be accepted or rejected. To help you make the decision, you have a dataset of test results on past microchips, from which you can build a logistic regression model.\n1df_data = pd.read_csv(\u0026#34;ex2data2.txt\u0026#34;,header=None,names=[\u0026#34;Test1\u0026#34;,\u0026#34;Test2\u0026#34;,\u0026#34;Passed_QA\u0026#34;]) 2df_data.head() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  visualizing the data 1positive_X = df_data[df_data[\u0026#34;Passed_QA\u0026#34;]==1] 2negative_X = df_data[df_data[\u0026#34;Passed_QA\u0026#34;]==0] 3plt.clf() 4plt.figure(dpi=300,figsize=(10,8)) 5plt.scatter(positive_X[\u0026#34;Test1\u0026#34;],positive_X[\u0026#34;Test2\u0026#34;],marker=\u0026#34;+\u0026#34;,c=\u0026#34;black\u0026#34;,s=50,label=\u0026#34;Passed QA\u0026#34;) 6plt.scatter(negative_X[\u0026#34;Test1\u0026#34;],negative_X[\u0026#34;Test2\u0026#34;],marker=\u0026#34;o\u0026#34;,c=\u0026#34;b\u0026#34;,s=50,label=\u0026#34;Not Passed QA\u0026#34;) 7plt.legend() 8plt.xlabel(\u0026#34;Microchip Test1\u0026#34;) 9plt.ylabel(\u0026#34;Microchip Test2\u0026#34;) 10plt.title(\u0026#34;Training Data\u0026#34;) Text(0.5, 1.0, 'Training Data') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Feature Mapping One way to fit the data better is to create more features from each data point. We will map the features into all polynomial terms of x1 and x2 up to the sixth power.\n1def feature_mapping(X,degree,start_cols=1): 2 X = np.array(X) 3 for i in range(0,degree+1): 4 for j in range(0,degree-i+1): 5 if(i==0 and j==0) or (i==0 and j==1) or (i==1 and j==0): 6 continue 7 X = np.c_[X,np.power(X[:,start_cols],i) \\ 8 * np.power(X[:,start_cols+1],j) ] 9 return np.matrix(X) 10 11df_X = df_data.drop(labels=\u0026#34;Passed_QA\u0026#34;,axis=1) 12df_X.insert(0,\u0026#34;Ones\u0026#34;,1) 13df_y = df_data[\u0026#34;Passed_QA\u0026#34;] 14mat_X = np.mat(df_X) 15mat_y = np.mat(df_y).T 16 17 18mat_X = feature_mapping(mat_X,start_cols=1,degree=6) 19print(mat_X.shape) (118, 28)  1iter_num = 100000 2alpha = 7.3 3theta,cost = logistic_regression_gradient_descent(mat_X,mat_y,iter_num,alpha) 4print(cost[-1]) 5 6plt.clf() 7plt.figure(dpi=300,figsize=(12,8)) 8plt.plot(range(1,iter_num+1),cost) 0.279387711431147 [\u0026lt;matplotlib.lines.Line2D at 0x7f80dfad87f0\u0026gt;] \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Plot Decision Boundary 1def plot_decision_boundary(theta,density,degree,norm_arg=[],normalization=False): 2 x,y = np.meshgrid( np.linspace(-1,1.5,density).reshape(-1,1), \\ 3 np.linspace(-1,1.5,density).reshape(-1,1) ) 4 new_X = np.ones((x.shape[0]**2)).astype(np.matrix) 5 if normalization: 6 x = (x - norm_arg[0]) / norm_arg[1] 7 y = (y - norm_arg[2]) / norm_arg[3] 8 new_X = np.c_[new_X,x.ravel(),y.ravel()] 9 x,y = np.meshgrid( np.linspace(-1,1.5,density).reshape(-1,1), \\ 10 np.linspace(-1,1.5,density).reshape(-1,1) ) 11 else : 12 new_X = np.c_[new_X,x.ravel(),y.ravel()] 13 new_X = feature_mapping(new_X,start_cols=1,degree=6) 14 15 decision = new_X * theta 16 decision = decision.reshape(x.shape) 17 18 plt.clf() 19 plt.figure(dpi=300,figsize=(12,10)) 20 plt.scatter(positive_X[\u0026#34;Test1\u0026#34;],positive_X[\u0026#34;Test2\u0026#34;],marker=\u0026#34;+\u0026#34;,c=\u0026#39;black\u0026#39;,s=50,label=\u0026#34;Passed_QA\u0026#34;) 21 plt.scatter(negative_X[\u0026#34;Test1\u0026#34;],negative_X[\u0026#34;Test2\u0026#34;],marker=\u0026#34;o\u0026#34;,c=\u0026#39;b\u0026#39;,s=50,label=\u0026#34;Not Passed QA\u0026#34;) 22 plt.contour(x,y,decision,levels=[0],linewidths=2,colors=[\u0026#39;r\u0026#39;]) 23 24 25density=100 26degree=6 27plot_decision_boundary(theta,density,degree) \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1# prediction 2x = mat_X[1,:] 3# print(x) 4predict = sigmoid(x * theta) 5print(predict) 6print(theta) [[0.95399812]] [[ 3.98319781] [ 1.36850003] [ 5.43718249] [ -4.18483606] [ -4.81980061] [-12.77108849] [ 7.73431623] [ 1.00059713] [ -9.00207478] [ 7.01416097] [ -1.22162831] [-10.09882437] [ -7.79890678] [ -6.23460064] [ 3.07355121] [ -6.66547573] [ -6.68395832] [-10.46038185] [ 3.8841028 ] [ 4.6499442 ] [ 11.74675575] [ 7.95790457] [ -2.01599155] [ -2.71991866] [ -0.8359666 ] [ -3.12881585] [ -2.20413302] [ -9.47196431]]  multi-variable logistic regression with feature scaling 1df_data = pd.read_csv(\u0026#34;ex2data2.txt\u0026#34;,header=None,names=[\u0026#34;Test1\u0026#34;,\u0026#34;Test2\u0026#34;,\u0026#34;Passed_QA\u0026#34;]) 2df_X = df_data.drop(labels=\u0026#34;Passed_QA\u0026#34;,axis=1) 3df_y = df_data[\u0026#34;Passed_QA\u0026#34;] 4df_norm_X = ( df_X-df_X.mean() ) / df_X.std() 5 6df_norm_X.insert(0,\u0026#34;Ones\u0026#34;,1) 7 8 9mat_norm_X = np.mat(df_norm_X) 10mat_norm_X = feature_mapping(mat_norm_X,start_cols=1,degree=6) 11mat_y = np.mat(df_y).T 12mat_norm_X.shape 13 (118, 28)  1iter_num = 5000 2alpha = 0.3 3theta,cost = logistic_regression_gradient_descent(mat_norm_X,mat_y,iter_num,alpha) 4print(cost[-1]) 5 6 7plt.clf() 8plt.figure(dpi=300,figsize=(12,8)) 9plt.plot(range(1,iter_num+1),cost) 0.2789910658508999 [\u0026lt;matplotlib.lines.Line2D at 0x7f80dd66e630\u0026gt;] \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1density=100 2degree=6 3norm_arg=[df_data[\u0026#34;Test1\u0026#34;].mean(),df_data[\u0026#34;Test1\u0026#34;].std() 4 ,df_data[\u0026#34;Test2\u0026#34;].mean(),df_data[\u0026#34;Test2\u0026#34;].std()] 5plot_decision_boundary(theta,density,degree,norm_arg,True) \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1 implementation with SciPy 1import scipy.optimize as opt 2 3degree=6 4 5df_data = pd.read_csv(\u0026#34;ex2data2.txt\u0026#34;,header=None,names=[\u0026#34;Test1\u0026#34;,\u0026#34;Test2\u0026#34;,\u0026#34;Passed_QA\u0026#34;]) 6df_X = df_data.drop(\u0026#34;Passed_QA\u0026#34;,axis=1) 7df_y = df_data[\u0026#34;Passed_QA\u0026#34;] 8arr_X = np.ones(len(df_X)) 9mat_X = np.mat(np.c_[arr_X,np.array(df_X)]) 10mat_X = feature_mapping(mat_X,start_cols=1,degree=6) 11mat_y = np.mat(df_y).T 12theta = np.zeros((mat_X.shape[1])) 13 14# 注意：opt.fmin_tnc或者opt.minimize 15# 会把变量x0当作np.array处理，所以在写函数时要做相应处理 16# res = opt.minimize(fun=cost_comput, x0=theta, args=(mat_X,mat_y), method=\u0026#39;Powell\u0026#39;, jac=gradient) 17res = opt.minimize(fun=cost_comput, x0=theta, args=(mat_X,mat_y), method=\u0026#39;L-BFGS-B\u0026#39;, jac=gradient,options={\u0026#39;maxiter\u0026#39;: 400, \u0026#39;disp\u0026#39;: True}) 18theta = np.mat(res[\u0026#34;x\u0026#34;]) 19 20print(cost_comput(theta,mat_X,mat_y)) 21plot_decision_boundary(theta.T,density,degree) 22 0.2702802021340963 \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Regularized logistic regression 1def reg_cost_comput(theta,X,y,reg_lambda): 2 theta = np.mat(theta).T 3 first = np.multiply(np.log(sigmoid(X*theta)),y) 4 second = np.multiply(np.log(1-sigmoid(X*theta)),y-1) 5 reg = (theta[1:,0].T * theta[1:,0]) * (reg_lambda / (2*X.shape[0])) 6 return float(sum(second-first) / X.shape[0] + reg) 7 8def reg_gradient(theta,X,y,reg_lambda): 9 theta = np.mat(theta).T 10 error = sigmoid(X*theta)-y 11 grad = ( X.T * error ).T / len(X) 12 13 reg = theta[1:,0] * (reg_lambda / len(X)) 14 grad[0,1:] = grad[0,1:]+reg.T 15 return grad 1degree=6 2reg_lambda=1 3 4df_data = pd.read_csv(\u0026#34;ex2data2.txt\u0026#34;,header=None,names=[\u0026#34;Test1\u0026#34;,\u0026#34;Test2\u0026#34;,\u0026#34;Passed_QA\u0026#34;]) 5df_X = df_data.drop(\u0026#34;Passed_QA\u0026#34;,axis=1) 6df_y = df_data[\u0026#34;Passed_QA\u0026#34;] 7arr_X = np.ones(len(df_X)) 8mat_X = np.mat(np.c_[arr_X,np.array(df_X)]) 9mat_X = feature_mapping(mat_X,degree,start_cols=1) 10mat_y = np.mat(df_y).T 11theta = np.zeros((mat_X.shape[1])) 12 13 14# reg_cost_comput(theta,mat_X,mat_y,reg_lambda) 15# reg_gradient(theta,mat_X,mat_y,reg_lambda) 16 17res = opt.minimize(fun=reg_cost_comput, x0=theta, args=(mat_X,mat_y,reg_lambda), method=\u0026#39;L-BFGS-B\u0026#39;, jac=reg_gradient,options={\u0026#39;maxiter\u0026#39;: 400}) 18# print(res) 19 20theta = np.mat(res[\u0026#34;x\u0026#34;]) 21plot_decision_boundary(theta.T,density,degree) \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1degree=6 2reg_lambda=100 3 4df_data = pd.read_csv(\u0026#34;ex2data2.txt\u0026#34;,header=None,names=[\u0026#34;Test1\u0026#34;,\u0026#34;Test2\u0026#34;,\u0026#34;Passed_QA\u0026#34;]) 5df_X = df_data.drop(\u0026#34;Passed_QA\u0026#34;,axis=1) 6df_y = df_data[\u0026#34;Passed_QA\u0026#34;] 7arr_X = np.ones(len(df_X)) 8mat_X = np.mat(np.c_[arr_X,np.array(df_X)]) 9mat_X = feature_mapping(mat_X,degree,start_cols=1) 10mat_y = np.mat(df_y).T 11theta = np.zeros((mat_X.shape[1])) 12 13 14# reg_cost_comput(theta,mat_X,mat_y,reg_lambda) 15# reg_gradient(theta,mat_X,mat_y,reg_lambda) 16 17res = opt.minimize(fun=reg_cost_comput, x0=theta, args=(mat_X,mat_y,reg_lambda), method=\u0026#39;L-BFGS-B\u0026#39;, jac=reg_gradient,options={\u0026#39;maxiter\u0026#39;: 400}) 18# print(res) 19 20theta = np.mat(res[\u0026#34;x\u0026#34;]) 21plot_decision_boundary(theta.T,density,degree) \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1degree=6 2reg_lambda=0 3 4df_data = pd.read_csv(\u0026#34;ex2data2.txt\u0026#34;,header=None,names=[\u0026#34;Test1\u0026#34;,\u0026#34;Test2\u0026#34;,\u0026#34;Passed_QA\u0026#34;]) 5df_X = df_data.drop(\u0026#34;Passed_QA\u0026#34;,axis=1) 6df_y = df_data[\u0026#34;Passed_QA\u0026#34;] 7arr_X = np.ones(len(df_X)) 8mat_X = np.mat(np.c_[arr_X,np.array(df_X)]) 9mat_X = feature_mapping(mat_X,degree,start_cols=1) 10mat_y = np.mat(df_y).T 11theta = np.zeros((mat_X.shape[1])) 12 13 14# reg_cost_comput(theta,mat_X,mat_y,reg_lambda) 15# reg_gradient(theta,mat_X,mat_y,reg_lambda) 16 17res = opt.minimize(fun=reg_cost_comput, x0=theta, args=(mat_X,mat_y,reg_lambda), method=\u0026#39;L-BFGS-B\u0026#39;, jac=reg_gradient,options={\u0026#39;maxiter\u0026#39;: 400}) 18# print(res) 19 20theta = np.mat(res[\u0026#34;x\u0026#34;]) 21plot_decision_boundary(theta.T,density,degree) \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  ","date":"Sep 4, 2021","img":"","permalink":"/en/posts/ml_cs229_exercise2/","series":null,"tags":null,"title":"ML_CS229_exercise2"},{"categories":null,"content":"Programming Exercise of Machine Learning andrew ng\u0026rsquo;CS 229\nExercise 1: Linear Regression Linear regression with one variable In this part of this exercise, you will implement linear regression with one variable to predict profits for a food truck. Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities.\nYou would like to use this data to help you select which city to expand to next.\nThe file ex1data1.txt contains the dataset for our linear regression problem. The first column is the population of a city and the second column is the profit of a food truck in that city. A negative value for profit indicates a loss.\nimport and visualize data 1import pandas as pd 2import matplotlib.pyplot as plt 3import numpy as np 1df = pd.read_csv(\u0026#39;ex1data1.txt\u0026#39;,header=None,names=[\u0026#39;Population\u0026#39;,\u0026#39;Profit\u0026#39;]) 2df.head() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  1plt.clf() 2plt.figure(dpi=300,figsize=(8,8)) 3plt.scatter(df[\u0026#39;Population\u0026#39;],df[\u0026#39;Profit\u0026#39;]) 4plt.title(\u0026#39;Scatter plot of training data\u0026#39;) 5plt.xlabel(\u0026#39;Population\u0026#39;) 6plt.ylabel(\u0026#39;Profit\u0026#39;) Text(0, 0.5, 'Profit') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1df[\u0026#34;one\u0026#34;]=1 2X = np.mat(df[[\u0026#39;one\u0026#39;,\u0026#39;Population\u0026#39;]].values) 3y = np.mat(df[\u0026#39;Profit\u0026#39;].values).transpose() 4print(X.shape) 5print(y.shape) (97, 2) (97, 1)  1iter_num = 1000def gradient_descent(X,y,iter_num,alpha=0.02,cost_comput=True): m = X.shape[0] theta = np.mat(np.zeros((X.shape[1],1))) cost=[] theta_arr=[] distance = X*theta-y for i in range(iter_num): theta = theta - sum(np.multiply(X,distance)).T * alpha/m theta_arr.append(theta) distance = X*theta-y if cost_comput == True: cost.append( float(distance.T * distance / (2*m)) )# 下面也可以# cost.append(float(sum(np.power(distance,2))) / (2 * m) ) return theta,cost,theta_arrtheta,cost,theta_arr = gradient_descent(X,y,iter_num)print(theta) [[-3.78841926] [ 1.18224801]]  1%matplotlib inlineplt.clf()plt.figure(dpi=300,figsize=(12,8))plt.plot(range(0,iter_num),cost)plt.title(\u0026#39;Scatter plot of training data\u0026#39;)plt.xlabel(\u0026#39;Popualation\u0026#39;)plt.ylabel(\u0026#39;Profit\u0026#39;) Text(0, 0.5, 'Profit') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1x = np.linspace(df.Population.min(), df.Population.max(), X.shape[0])f = theta[0,0]+ (x*theta[1,0])plt.clf()plt.figure(dpi=300,figsize=(12,8))plt.plot(x,f,\u0026#39;r\u0026#39;,label=\u0026#39;Prediction\u0026#39;)plt.scatter(df[\u0026#39;Population\u0026#39;],df[\u0026#39;Profit\u0026#39;],label=\u0026#39;Training Data\u0026#39;)plt.legend(loc=2)plt.xlabel(\u0026#39;Population\u0026#39;)plt.ylabel(\u0026#39;Profit\u0026#39;)plt.title(\u0026#39;Predicted Profit vs. Population Size\u0026#39;) Text(0.5, 1.0, 'Predicted Profit vs. Population Size') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  visualizing $J(\\theta)$ 1theta0_vals, theta1_vals = np.meshgrid( # reshape如果中有参数等于-1的话， # 那么Numpy会根据剩下的维度计算出数组的另外一个shape属性值 np.linspace(-10, 10, 100).reshape(-1, 1), np.linspace(-1, 4, 100).reshape(-1, 1), )J_vals = np.c_[theta0_vals.ravel(), theta1_vals.ravel()]J_vals = np.power(J_vals * X.T - y.T,2).TJ_vals=sum(J_vals).T / (X.shape[0] * 2)J_vals = J_vals.reshape(theta0_vals.shape) 1plt.clf()plt.figure(dpi=300,figsize=(10,8))plt.contour(theta0_vals, theta1_vals, J_vals,linewidths=1,levels=np.logspace(-2,3,20),cmap=\u0026#39;rainbow\u0026#39;)plt.scatter(theta[0,0],theta[1,0],marker=\u0026#34;x\u0026#34;,c=\u0026#34;r\u0026#34;,s=50)plt.title(\u0026#34;Contour,showing minimum\u0026#34;) Text(0.5, 1.0, 'Contour,showing minimum') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1theta_x,theta_y = zip(*theta_arr)plt.clf()plt.figure(dpi=300,figsize=(10,8))plt.contour(theta0_vals, theta1_vals, J_vals,linewidths=1,levels=np.logspace(-2,3,20),cmap=\u0026#39;rainbow\u0026#39;)plt.scatter(theta_x,theta_y,marker=\u0026#34;x\u0026#34;,c=\u0026#34;r\u0026#34;,s=50)plt.title(\u0026#34;Track of Theta\u0026#34;) Text(0.5, 1.0, 'Track of Theta') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  1from matplotlib import pyplot as pltplt.clf()fig = plt.figure(dpi=300,figsize=(12,10)) ax3 = plt.axes(projection=\u0026#39;3d\u0026#39;)ax3.view_init(elev=25, azim=-130) # 旋转图像初始视角ax3.plot_surface(theta0_vals,theta1_vals,J_vals,cmap=\u0026#39;rainbow\u0026#39;)plt.title(\u0026#34;Surface\u0026#34;) Text(0.5, 0.92, 'Surface') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Linear regression with multiple variables In this part, you will implement linear regression with multiple variables to predict the prices of houses. Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to first collect information on recent houses sold and make a model of housing prices.\nThe file ex1data2.txt contains a training set of housing prices in Portland, Oregon. The first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price of the house.\n1multi_df = pd.read_csv(\u0026#39;ex1data2.txt\u0026#39;,header=None,names=[\u0026#39;Size\u0026#39;, \u0026#39;Bedrooms\u0026#39;, \u0026#39;Price\u0026#39;])multi_df.head() .dataframe tbody tr th { vertical-align: top;}.dataframe thead th { text-align: right;}  Feature Normalization/Feature Scaling By looking at the values, note that house sizes are about 1000 times the number of bedrooms. When features differ by orders of magnitude, first performing feature scaling can make gradient descent converge much more quickly.\n标准化 / z值归一化（standardization / z-score normalization） 1multi_X = multi_df[[\u0026#34;Size\u0026#34;,\u0026#34;Bedrooms\u0026#34;]]multi_X = (multi_X - multi_X.mean()) / multi_X.std()multi_X[\u0026#34;one\u0026#34;] = 1multi_X.head() .dataframe tbody tr th { vertical-align: top;}.dataframe thead th { text-align: right;}  Selecting learning rates In this part of the exercise, you will get to try out different learning rates for the dataset and find a learning rate that converges quickly.\nif your value of $ J\\left( \\theta \\right) $ increases or even blows up,adjust your learning rate and try again. We recommend trying values of the learning rate α on a log-scale, at multiplicative steps of about 3 times the previous value (i.e., 0.3, 0.1, 0.03, 0.01 and so on).\nIf your learning rate is too large, J(θ) can diverge and ‘blow up’, resulting in values which are too large for computer calculations.\n如果学习率太大会导致$\\theta$的值溢出，使执行出现警告，并且$\\theta$会返回NaN代表值为$\\infty$\n1X = np.mat(multi_X)y = np.mat(multi_df[\u0026#39;Price\u0026#39;]).Titer_num = 50theta,cost,theta_arr = gradient_descent(X,y,iter_num,alpha=1.2) 1plt.clf()plt.figure(dpi=300,figsize=(12,8))plt.plot(range(0,iter_num),cost)plt.title(\u0026#39;Scatter plot of training data\u0026#39;)plt.xlabel(\u0026#39;Popualation\u0026#39;)plt.ylabel(\u0026#39;Profit\u0026#39;) Text(0, 0.5, 'Profit') \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Normal Equations 正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\\frac{\\partial }{\\partial {{\\theta }{j}}}J\\left( {{\\theta }{j}} \\right)=0$ 。 假设我们的训练集特征矩阵为 X（包含了${{x}_{0}}=1$）并且我们的训练集结果为向量 y，则利用正规方程解出向量: $$\\theta ={{\\left( {{X}^{T}}X \\right)}^{-1}}{{X}^{T}}y$$\nUsing this formula does not require any feature scaling, and you will get an exact solution in one calculation: there is no “loop until convergence” like in gradient descent.\n梯度下降与正规方程的比较： 梯度下降：需要选择学习率α，需要多次迭代，当特征数量n大时也能较好适用，适用于各种类型的模型\n正规方程：不需要选择学习率α，一次计算得出，需要计算${{\\left( {{X}^{T}}X \\right)}^{-1}}$，如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为$O(n3)$，通常来说当$n$小于10000 时还是可以接受的，只适用于线性模型，不适合逻辑回归模型等其他模型\n1def normal_equation(X,y): return (X.T * X).I * X.T * y 1# ex1data1.txtdf = pd.read_csv(\u0026#39;ex1data1.txt\u0026#39;,header=None,names=[\u0026#39;Population\u0026#39;,\u0026#39;Profit\u0026#39;])df[\u0026#34;one\u0026#34;] = 1X = np.mat(df[[\u0026#39;one\u0026#39;,\u0026#39;Population\u0026#39;]].values)y = np.mat(df[\u0026#39;Profit\u0026#39;].values).Ttheta = normal_equation(X,y)print(theta) [[-3.89578088] [ 1.19303364]]  1multi_df = pd.read_csv(\u0026#39;ex1data2.txt\u0026#39;,header=None,names=[\u0026#39;Size\u0026#39;, \u0026#39;Bedrooms\u0026#39;, \u0026#39;Price\u0026#39;])multi_df[\u0026#34;one\u0026#34;] = 1X = np.mat(multi_df[[\u0026#39;one\u0026#39;,\u0026#39;Size\u0026#39;,\u0026#39;Bedrooms\u0026#39;]].values)y = np.mat(multi_df[\u0026#39;Price\u0026#39;].values).Ttheta = normal_equation(X,y)print(theta) [[89597.9095428 ] [ 139.21067402] [-8738.01911233]]  Prediction Now, once you have found $\\theta$ using this method, use it to make a price prediction for a 1650-square-foot house with 3 bedrooms. You should find that gives the same predicted price as the value you obtained using the model fit with gradient descent\n1price = theta[0,0] + 1650*theta[1,0] + 3*theta[2,0]print(price) 293081.46433489426  Difference Between array and matrix in numpy matrix是array的分支\nDimension numpy array(ndarrays) can be N-dimension\nnumpy matrix must be 2-dimension\n注意：\n1.一维的numpy数组不是向量或矩阵,此时shape属性中是没有列值的,如果需要当作向量来操,可以使用list of list来生成array\n2.matrix和array在很多时候都是通用的，由于array可以表示更高维度的数据，更灵活，速度更快，官方建议选择array,必要时再转换成matrix\nAttribute numpy array和matrix 都有.T属性来表示它们的转置\nmatrix还有.H属性表示共轭转置,.I表示逆矩阵\nMethod 两者可以互相用.asmatrix()或.asarray()互相转换\n1import numpy as np 2arr = np.array([1,2,3]) # arr 不算矩阵 3print(arr.shape) 4print(arr.T.shape) 5 6mat = np.mat([1,2,3]) 7print(mat.shape) 8print(mat.T.shape) 9 Operation array numpy array 大多数操作符号都是element-wise的,比如*操作和np.multiply()函数,都是对应元素相乘(element-wise multiplication)\n例如：\n$$ x = \\begin{bmatrix} 1 \u0026amp; 2\\\n3 \u0026amp; 4 \\end{bmatrix}, y=\\begin{bmatrix} 1 \\ 2 \\end{bmatrix}, z=\\begin{bmatrix} 1 \u0026amp; 2 \\end{bmatrix}$$ $$ xy=\\begin{bmatrix} 1 \u0026amp; 2\\\n6 \u0026amp; 8 \\end{bmatrix}, xz=\\begin{bmatrix} 1 \u0026amp; 4\\\n3 \u0026amp; 8 \\end{bmatrix} $$\n对应元素相乘一般需要向量的行或列与矩阵相等,或者两个矩阵行与列相等\n@操作和.dot()方法或np.dot()函数,进程矩阵乘法\nmatrix matrix的优势就是相对简单的运算符号,可以直接用*操作表示矩阵乘法,但是也兼容array的函数和方法\n1x = np.array([ [1,2],[3,4] ]) 2y = np.array([[1,2]]) 3print(y.shape) 4print(x*y.T) 5print(np.multiply(x,y.T)) ","date":"Sep 4, 2021","img":"","permalink":"/en/posts/ml_cs229_exercise1/","series":null,"tags":null,"title":"ML_CS229_exercise1"},{"categories":null,"content":"Hi🙋‍♂️，Welcome to my blog🎉!\nI am a graduate student of computer science in SiChuan Normal University(SICNU),my research interests mainly in artificial intelligence, machine learning, data mining, web development.\nMy blog build for sharing knowledge l was learned and recording my thoughts💡, Hope you enjoy it😊.\n","date":"Sep 2, 2021","img":"","permalink":"/en/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"Python Tutorial of Machine-Learning Python Shell Python shell, a place where you can type Python code and immediately see the results.\nPython Shell The Python shell that\u0026rsquo;s used here is actually not the original one; we\u0026rsquo;re using IPython, short for Interactive Python(简称为交互式Python), which is some kind of juiced up version of regular Python that\u0026rsquo;ll be useful later on(Python的加强版本). IPython was created by Fernando Pérez and is part of the broader Jupyter ecosystem. Apart from interactively working with Python, you can also have Python run so called python scripts.(除了和python交互外，也可以直接运行python脚本)\nChapter 1:Basic Data Type Python has a number of basic types including integers, floats, booleans, and strings. # These data types behave in ways that are familiar from other programming languages.\nStrings 1#format strings 2str = \u0026#34;my name is %s,%dyear-old\u0026#34; % (\u0026#34;long\u0026#34;,25) 3print(str) my name is long,25 year-old  如果字符串里面有引号，那么定义字符串就应该使用不同的引号。\n里面是单引号，外面就用双引号。\n里面是双引号，外面就用单引号。\n1str1 = \u0026#34;他说：\u0026#39;你好\u0026#39;\u0026#34; 2print(str1) 3str2 = \u0026#39;他说：\u0026#34;你好\u0026#34;\u0026#39; 4print(str2) 他说：'你好' 他说：\u0026quot;你好\u0026quot;  A string can multiplied by an integer\n1print(\u0026#39;a\u0026#39;*2) 2print(\u0026#39;Long\u0026#39;*3) aa LongLongLong  Str methods capitalize():使字符串首字母大写\nreplace(old, new[, count]) -\u0026gt; str\n1sister = \u0026#39;liz\u0026#39; 2print(sister.capitalize()) 3print(sister.replace(\u0026#39;z\u0026#39;,\u0026#39;sa\u0026#39;)) Liz lisa  Complex Number Python has build-in type of complex number\n1# Create a complex number, 2ComplexNum = (12+3j) # or ues ComplexNum = complex(12,3) 3print(ComplexNum) 1#real component \u0026amp; imagine component 2print(ComplexNum.real) # print the real component 3print(ComplexNum.imag) # print the imagine component Operator The following operators are different from c language\n   operator description     ** Exponentiation(指数运算)   // 取整除    The operator behaved differently for different data types.\n\u0026ldquo;+\u0026rdquo; operator:\nFor the integers, the values were summed\nFor the strings, the strings were pasted together\n1print(1+2) 2print(\u0026#34;My first name is: \u0026#34;+\u0026#34;Long\u0026#34;) 3print(True+True) 3 My first name is: Long 2  Containers:List \u0026amp; Dictionary \u0026amp; sets \u0026amp; tuples List A list is an ordered and resizeable array of elements\nA list can contain elements of different types,almost any Python object include containers type and even function\nordered:索引序号与元素的对应关系与创建时保持一致\narray:有sequence特性\n1#Create a list 2my_list=[] #create a empty list 3my_list = [1,2,\u0026#34;too\u0026#34;] 4print(my_list) [1, 2, 'too']  1my_list1 = [1,2,3,4] 2my_list2 = [5,6] 3dictionary = {\u0026#34;age\u0026#34;:25} 4s = {\u0026#34;cat\u0026#34;,\u0026#34;dog\u0026#34;,\u0026#34;cat\u0026#34;} 5tup = (10,11) 6 7my_list1.append(my_list2) 8my_list1.append(dictionary) 9my_list1.append(s) 10my_list1.append(tup) 11print(my_list1) 12my_list2.append(7) 13print(my_list1) [1, 2, 3, 4, [5, 6], {'age': 25}, {'dog', 'cat'}, (10, 11)] [1, 2, 3, 4, [5, 6, 7], {'age': 25}, {'dog', 'cat'}, (10, 11)]  1def replace(arg): 2 arg[0] = \u0026#34;long\u0026#34; 3my_list = [1,2,3] 4my_list.append(replace) 5print(my_list) 6my_list[3](my_list) 7print(my_list) [1, 2, 3, \u0026lt;function replace at 0x7f9819b27488\u0026gt;] ['long', 2, 3, \u0026lt;function replace at 0x7f9819b27488\u0026gt;]  Indices Notice:the end of the slice is exclusive and that the index starts at zero!\nNegetive indices support\nmy_list = [1,2,\u0026ldquo;too\u0026rdquo;]\n   1 2 \u0026ldquo;too\u0026rdquo;     0 1 2   -3 -2 -1    Slicing [start:end]\n   start end     include exclude    However, it\u0026rsquo;s also possible not to specify these indexes. If you don\u0026rsquo;t specify the begin index, Python figures out that you want to start your slice at the beginning of your list. If you don\u0026rsquo;t specify the end index, the slice will go all the way to the last element of your list.\n1print(my_list[-1]) 2print(my_list[1:]) # Get a slice from index 1 to the end 1#Loop over the elements in list 2for x in my_list : 3 print(x) 4#Loop over the indices and elements 5for i,x in enumerate(my_list) : 6 print(str(i+1) + \u0026#34;:\u0026#34; +str(x)) 1#List Comprehension(列表推导式)用于创建list 2#new_list=[expression_for_member for member in iterable if condition] 3my_list=[x**2 for x in range(5) if x%2 == 0] 4print(my_list) [0, 4, 16]  1# Quick sort complementation using list 2def QuickSort(arr) : 3 if len(arr) \u0026lt;= 1 : 4 return arr 5 pivot = arr[0] 6 left = [x for x in arr if x \u0026lt; pivot] 7 middle = [x for x in arr if x == pivot] 8 right = [x for x in arr if x \u0026gt; pivot] 9 return QuickSort(left) + middle + QuickSort(right) Manipulating List List\u0026rsquo;s methods can change the objects they are called on sometime, it can also be pretty dangerous, so watch out.\n\u0026lsquo;+\u0026rsquo; operator in list Use the \u0026lsquo;+\u0026rsquo; operator in list can build a list which paste the right list to the end of the right list\nReplace list elements Replacing list elements is pretty easy. Simply subset the list and assign new values to the subset. You can select single elements or you can change entire list slices at once.\nDelete list elements you can use the \u0026lsquo;del\u0026rsquo; build-in function to remove elements from your list.\nPay attention here: as soon as you remove an element from a list, the indexes of the elements that come after the deleted element all change! 注意选项一的误导性：先删除下标10的元素，会导致原list的下标发生变化，无法得到预期的结果\n1areas = [\u0026#34;hallway\u0026#34;, 11.25, \u0026#34;kitchen\u0026#34;, 18.0, \u0026#34;chill zone\u0026#34;, 20.0, 2 \u0026#34;bedroom\u0026#34;, 10.75, \u0026#34;bathroom\u0026#34;, 10.50] 3areas_1 = areas + [\u0026#34;poolhouse\u0026#34;, 24.5] 4print(areas_1) 5areas_1[:1] = [\u0026#34;chill zone\u0026#34;,10.5] 6print(areas_1) 7del(areas_1[-2:]) 8print(areas_1) ['hallway', 11.25, 'kitchen', 18.0, 'chill zone', 20.0, 'bedroom', 10.75, 'bathroom', 10.5, 'poolhouse', 24.5] ['chill zone', 10.5, 11.25, 'kitchen', 18.0, 'chill zone', 20.0, 'bedroom', 10.75, 'bathroom', 10.5, 'poolhouse', 24.5] ['chill zone', 10.5, 11.25, 'kitchen', 18.0, 'chill zone', 20.0, 'bedroom', 10.75, 'bathroom', 10.5]  Inner workings of lists Identfier of list does not actually contain all the list elements, it rather contains a reference to the list!\nLet\u0026rsquo;s store the list x as a new variable y, by simply using the equals sign.\nLet\u0026rsquo;s now change the element with index one in the list y, like this. When you\u0026rsquo;re updating an element the list, it\u0026rsquo;s one and the same list in the computer memory your changing. Both x and y point to this list, so the update is visible from both variables. If you want to create a list y that points to a new list in the memory with the same values,you\u0026rsquo;ll need to use something else than the equals sign. You can use the list function,like this, or use slicing [:] to select all list elements explicitly.\nIf you now make a change to the list y points to, x is not affected.\nList methods index():to get the index of a element\ncount():to count the number of a element in list\nreverse():to reverses the order of the elements in the list it is called on\n1fam = [\u0026#39;lisa\u0026#39;,1.72,\u0026#39;emma\u0026#39;,1.72] 2print(fam.index(\u0026#39;lisa\u0026#39;)) 3print(fam.count(1.72)) 0 2  Dictionary A dictionary stores (key:value)pairs\nDictionaries are inherently unordered\nthe keys in a dictionary should be unique. If you try to add another key:value pair to world with the same key, the last pair that you specified in the curly brackets was kept in the resulting dictionary.\nAlso, these unique keys in a dictionary should be so-called immutable objects.\nBasically, the content of immutable objects cannot be changed after they\u0026rsquo;re created.\nDictionaries can contain key:value pairs where the values are again dictionaries.\n1#Create a dictionary 2d = {} #create a empty dictionary 3d = {\u0026#34;name\u0026#34;:\u0026#34;zhang\u0026#34;,\u0026#34;gender\u0026#34;:\u0026#34;famale\u0026#34;,\u0026#34;height\u0026#34;:173,\u0026#34;name\u0026#34;:\u0026#34;long\u0026#34;} 4print(d) 5europe = { \u0026#39;spain\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;madrid\u0026#39;, \u0026#39;population\u0026#39;:46.77 }, 6 \u0026#39;france\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;paris\u0026#39;, \u0026#39;population\u0026#39;:66.03 }, 7 \u0026#39;germany\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;berlin\u0026#39;, \u0026#39;population\u0026#39;:80.62 }, 8 \u0026#39;norway\u0026#39;: { \u0026#39;capital\u0026#39;:\u0026#39;oslo\u0026#39;, \u0026#39;population\u0026#39;:5.084 } } 9print(europe) {'name': 'long', 'gender': 'famale', 'height': 173} {'spain': {'capital': 'madrid', 'population': 46.77}, 'france': {'capital': 'paris', 'population': 66.03}, 'germany': {'capital': 'berlin', 'population': 80.62}, 'norway': {'capital': 'oslo', 'population': 5.084}}  1#add or delete a pair in dictionary 2d[\u0026#34;weight\u0026#34;] = 71 3print(d) 4del(d[\u0026#34;gender\u0026#34;]) # del d[\u0026#34;gender\u0026#34;] 5print(d) {'name': 'long', 'gender': 'famale', 'height': 173, 'weight': 71} {'name': 'long', 'height': 173, 'weight': 71}  1#Loop over the keys in dictionary 2for attribute in d: 3 print(d[attribute]) 4#Loop over keys and their corresponding values,use the item() 5for attribute,value in d.items(): 6 print(\u0026#34;%s:%s\u0026#34; % (str(attribute),str(value))) 7print(\u0026#34;height\u0026#34; in d) long famale 173 name:long gender:famale height:173 True  1# dictionary comprehension 2my_list = [\u0026#34;name\u0026#34;,\u0026#34;long\u0026#34;,\u0026#34;height\u0026#34;,173] 3dictionary = {my_list[i-1]:x for i,x in enumerate(my_list) if (i+1)%2==0} 4print(dictionary) {'name': 'long', 'height': 173}  methods keys() Check out which keys are in dictionary by calling the keys() method\nList vs Dictionary The list is a sequence of values that are indexed by a range of numbers.\nThe dictionary is indexed by unique keys, that can be any immutable type.\n   List Dictionary     indexed by range of numbers indexed by unique keys   collection of values; Lookup table with unique keys   order matters;    select entire subsets     When to use which one if you have a collection of values where the order matters, and you want to easily select entire subsets of data, you\u0026rsquo;ll want to go with a list.\nIf, on the other hand, you need some sort of look up table, where looking for data should be fast and where you can specify unique keys, a dictionary is the preferred option.\n1d = {\u0026#34;name\u0026#34;:\u0026#34;long\u0026#34;,\u0026#34;gender\u0026#34;:\u0026#34;famale\u0026#34;,\u0026#34;height\u0026#34;:173} 2print(d.keys()) dict_keys(['name', 'gender', 'height'])  Set(集合) A set is an unordered collection of distinct elements\nunordered:所谓无序是指数据结构上的无序，区别于列表，即set的索引序号与元素的对应关系不一定与创建时一致\ndistinct:不重复性，set中的元素不会重复\n1#create a set 2s = set() #create a empty set,note the difference from creation of a empty dictionary 3 #set([iterable]) iterable -- 可迭代对象对象； 4s = set(\u0026#34;ddsasad\u0026#34;) 5print(s) 6s = {\u0026#34;cat\u0026#34;,\u0026#34;dog\u0026#34;,\u0026#34;fish\u0026#34;} 7print(s) 8 1#Iterating over a set has the same syntax as iterating over a list;  2#however since sets are unordered, you cannot make assumptions about the order in which you visit the elements of the set 3for i,x in enumerate(s): 4 print(str(i)+\u0026#34;:\u0026#34;+str(x)) 1# 下面展示两个集合间的运算. 2... 3\u0026gt;\u0026gt;\u0026gt; a = set(\u0026#39;abracadabra\u0026#39;) 4\u0026gt;\u0026gt;\u0026gt; b = set(\u0026#39;alacazam\u0026#39;) 5\u0026gt;\u0026gt;\u0026gt; a 6{\u0026#39;a\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;} 7\u0026gt;\u0026gt;\u0026gt; a - b # 集合a中包含而集合b中不包含的元素 8{\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;} 9\u0026gt;\u0026gt;\u0026gt; a | b # 集合a或b中包含的所有元素 10{\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;l\u0026#39;} 11\u0026gt;\u0026gt;\u0026gt; a \u0026amp; b # 集合a和b中都包含了的元素 12{\u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;} 13\u0026gt;\u0026gt;\u0026gt; a ^ b # 不同时包含于a和b的元素 14{\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;l\u0026#39;} {'b', 'd', 'l', 'm', 'r', 'z'}  1type([1,2]) 2s={\u0026#34;dsa\u0026#34;,\u0026#34;dsa\u0026#34;} 3# s.update({\u0026#34;dsa1\u0026#34;:\u0026#34;qw\u0026#34;,\u0026#34;dsa2\u0026#34;:12}) 4s |= set({\u0026#34;dsa1\u0026#34;:\u0026#34;qw\u0026#34;,\u0026#34;dsa2\u0026#34;:12}) 5print(s) {'dsa2', 'dsa', 'dsa1'}  Tuple a tuple is an immutable ordered list of values\nimmutable:tuple isn\u0026rsquo;t allowed to delete,update and add its elements.\n1# create a tuple 2tup = () # create a empty tuple 3tup = (\u0026#39;cat\u0026#39;,\u0026#34;dog\u0026#34;,1111,52) 4print(tup) ('cat', 'dog', 1111, 52)  A tuple is in many ways similar to a list;\none of the most important differences is that tuples can be used as keys in dictionaries and as elements of sets, while lists cannot.\n1dictionary = {(x-1,x):x**2 for x in range(4) if x%2==0} 2print(dictionary) {(-1, 0): 0, (1, 2): 4}  Identfier of containers jsut like the pointer in c language 1def replace(arg): 2 arg[\u0026#39;name\u0026#39;] = \u0026#34;Jinyu\u0026#34; 3dictionary = {\u0026#34;name\u0026#34;:\u0026#34;long\u0026#34;,\u0026#34;age\u0026#34;:25} 4print(dictionary) 5replace(dictionary) 6print(dictionary) {'name': 'long', 'age': 25} {'name': 'Jinyu', 'age': 25}  Numpy Numpy is a core library for scientific computing\nIt provide a high-performance multidimensional array object and tools for working with these arrays\nMotivation A list can hold any type and can hold different types at the same time. You can also change, add and remove elements,this is wonderful.However,When analyzing data, you\u0026rsquo;ll often want to carry out operations over entire collections of values, and you want to do this fast. With lists, this is a problem.\nIllustration Let\u0026rsquo;s retake the heights of your family and yourself. Suppose you\u0026rsquo;ve also asked for everybody\u0026rsquo;s weight. It\u0026rsquo;s not very polite, but everything for science, right? You end up with two lists, height, and weight. The first person is 1-point-73 meters tall and weighs 65-point-4 kilograms. If you now want to calculate the Body Mass Index for each family member, you\u0026rsquo;d hope that this call can work, making the calculations element-wise. Unfortunately, Python throws an error, because it has no idea how to do calculations on lists. You could solve this by going through each list element one after the other, and calculating the BMI for each person separately, but this is terribly inefficient and tiresome to write.\nSolution: Numpy A way more elegant solution is to use NumPy, or Numeric Python. It\u0026rsquo;s a Python package that, among others, provides a alternative to the regular python list: the Numpy array. The Numpy array is pretty similar to the list, but has one additional feature: you can perform calculations over entire arrays. It\u0026rsquo;s really easy, and super-fast as well.\n1import numpy as np 2height = [1.73, 1.68, 1.71, 1.89, 1.79] 3weight = [65.4, 59.2, 63.6, 88.4, 68.7] 4#Create a numpy array 5np_weight = np.array(weight) 6np_height = np.array(height) 7bmi = np_weight / np_height**2 8print(bmi) [21.85171573 20.97505669 21.75028214 24.7473475 21.44127836]  Numpy Subsetting you can work with Numpy arrays pretty much the same as you can with regular Python lists.\nSpecifically for Numpy, there\u0026rsquo;s also another way to do list subsetting: using an array of booleans.\nA first step is using the comparsion Operators\nThe result is a Numpy array containing booleans: True if the corresponding elements comform the comparsion condition,False if it\u0026rsquo;s not.\nNext, you can use this boolean array inside square brackets to do subsetting,so for which the corresponding boolean value is True, is selected.\nTypically, Python can\u0026rsquo;t tell how two objects with different types relate.(通常来说python不能进行两种不同数据类型的比较)\nBehind the scenes, Numpy builds a numpy array of the same size filled with the number and then performs an element-wise comparison.\n1is_lightweight = bmi \u0026lt;21 2print(bmi[is_lightweight]) [20.97505669]  Numpy: remarks Numpy array can only contain values of a single type. It\u0026rsquo;s either an array of floats, either an array of booleans, and so on.\nIf you do try to create an array with different types,the resulting Numpy array will contain a single type:\nThe boolean,the string and the float were both converted to strings.\nThe boolean and the float were both converted to float,\u0026lsquo;True\u0026rsquo; convert to \u0026lsquo;1\u0026rsquo;, and \u0026lsquo;False\u0026rsquo; convert to \u0026lsquo;0\u0026rsquo;\n1print(np.array([1.0, \u0026#34;is\u0026#34;, True])) 2print(np.array([1.0, False, True])) 3print(np.array([True, 1, 2]) + np.array([3, 4, False])) ['1.0' 'is' 'True'] [1. 0. 1.] [4 5 2]  Numpy boolen operato If you combine two numpy array with the and operator,it will induce a error.\nprint(bmi \u0026lt; 22 and bmi \u0026gt; 21)\nAfter some digging in the numpy documentation, you can find the functions logical_and, logical_or and logical_not, the \u0026ldquo;array equivalents\u0026rdquo; of and or and not.\n1print(np.logical_and(bmi \u0026lt; 22,bmi \u0026gt; 21)) 2print(bmi[np.logical_and(bmi \u0026lt; 22,bmi \u0026gt; 21)]) [ True False True False True] [21.85171573 21.75028214 21.44127836]  2D Numpy Arrays Type of Numpy Arrays If you ask for the type of these arrays, Python tells you that they are numpy.ndarray. numpy dot tells you it\u0026rsquo;s a type that was defined in the numpy package. ndarray stands for n-dimensional array.\nit\u0026rsquo;s perfectly possible to create 2 dimensional, three dimensional, heck even seven dimensional arrays!\n2D Numpy Arrays You can create a 2D numpy array from a regular Python list of lists.\nit is a rectangular data structure: Each sublist in the list, corresponds to a row in the two dimensional numpy array.\n\u0026lsquo;shape\u0026rsquo; is a so-called attribute of the numpy array, that can give you dimensional information of numpy array.\nSubsetting Basically you\u0026rsquo;re selecting the row, and then from that row do another selection. There\u0026rsquo;s also an alternative way of subsetting, using single square brackets and a comma. This call returns the exact same value as before. The value before the comma specifies the row, the value after the comma specifies the column.The intersection of the rows and columns you specified, are returned.\nOnce you get used to it, this syntax is more intuitive and opens up more possibilities.\nBy using slice,The intersection can gives us a 2D array\nThe \u0026lsquo;:\u0026rsquo; is for slicing, it tells Python to include some rows or columns.\n1np_2d = np.array([[1.73, 1.68, 1.71, 1.89, 1.79],\\ 2 [65.4, 59.2, 63.6, 88.4, 68.7]]) 3print(np_2d.shape) 4print(np_2d[1][0]) 5print(np_2d[1,0]) 6print(np_2d[:,:2]) (2, 5) 65.4 65.4 [[ 1.73 1.68] [65.4 59.2 ]]  2D Arithmetic 2D numpy arrays enable you to do element-wise calculations, the same way you did it with 1D numpy arrays.\nYou can combine matrices with single numbers, with vectors, and with other matrices.\n1import numpy as np 2np_mat = np.array([[1, 2], 3 [3, 4], 4 [5, 6]]) 5print(np_mat * 2) 6print(np_mat + np.array([10, 10])) # equal to \u0026#34;np_mat + 10\u0026#34; 7print(np_mat + np_mat) [[ 2 4] [ 6 8] [10 12]] [[11 12] [13 14] [15 16]] [[ 2 4] [ 6 8] [10 12]]  Difference Between array and matrix in numpy matrix是array的分支\nDimension numpy array(ndarrays) can be N-dimension\nnumpy matrix must be 2-dimension\n注意：\n1.一维的numpy数组不是向量或矩阵,此时shape属性中是没有列值的,如果需要当作向量来操,可以使用list of list来生成array\n2.matrix和array在很多时候都是通用的，由于array可以表示更高维度的数据，更灵活，速度更快，官方建议选择array,必要时再转换成matrix\nAttribute numpy array和matrix 都有.T属性来表示它们的转置\nmatrix还有.H属性表示共轭转置,.I表示逆矩阵\nMethod 两者可以互相用.asmatrix()或.asarray()互相转换\n1import numpy as np 2arr = np.array([1,2,3]) # arr 不算矩阵 3print(arr.shape) 4print(arr.T.shape) 5 6mat = np.mat([1,2,3]) 7print(mat.shape) 8print(mat.T.shape) (3,) (3,) (1, 3) (3, 1)  Operation array numpy array 大多数操作符号都是element-wise的,比如*操作和np.multiply()函数,都是对应元素相乘(element-wise multiplication)\n例如：\n$$ x = \\begin{bmatrix} 1 \u0026amp; 2\\\n3 \u0026amp; 4 \\end{bmatrix}, y=\\begin{bmatrix} 1 \\ 2 \\end{bmatrix}, z=\\begin{bmatrix} 1 \u0026amp; 2 \\end{bmatrix}$$ $$ xy=\\begin{bmatrix} 1 \u0026amp; 2\\\n6 \u0026amp; 8 \\end{bmatrix}, xz=\\begin{bmatrix} 1 \u0026amp; 4\\\n3 \u0026amp; 8 \\end{bmatrix} $$\n对应元素相乘一般需要向量的行或列与矩阵相等,或者两个矩阵行与列相等\n@操作和.dot()方法或np.dot()函数,进程矩阵乘法\nmatrix matrix的优势就是相对简单的运算符号,可以直接用*操作表示矩阵乘法,但是也兼容array的函数和方法\n1x = np.array([ [1,2],[3,4] ]) 2y = np.array([[1,2]]) 3print(y.shape) 4print(x*y.T) 5print(np.multiply(x,y)) (1, 2) [[1 2] [6 8]] [[1 4] [3 8]]  Numpy: Basic Statistics However, the big difference here is speed. Because Numpy enforces a single data type in an array, it can drastically speed up the calculations.\nMotivation:to know your data A typical first step in analyzing your data is getting to know your data in the first place.\nAs a data scientist, you\u0026rsquo;ll be crunching thousands, if not millions or billions of numbers.\nWhat you can do, though, is generate summarizing statistics about your data.\nMotivation:to do sanity check Often, these summarizing statistics will provide you with a \u0026ldquo;sanity check\u0026rdquo; of your data. If you end up with a average weight of 2000 kilograms, your measurements are most likely incorrect.\nsanity check:数据的健全性检查，通过平均值、中位数和标准差等统计数据来检查数据中是否存在异常值等问题\nmean value you can try to find out the average value of your data set, with Numpy\u0026rsquo;s mean() function.\nBecause it\u0026rsquo;s a function from the Numpy package, don\u0026rsquo;t forget to start with np\nmedian median is the middle value if you sort all data from small to big.\nyou can simply use Numpy\u0026rsquo;s \u0026lsquo;median()\u0026rsquo; function\n function in numpy\ncorrcoeff():to check if for example height and weight are correlated\nstd():for standard deviation\nand so on,such as sum and sort, which also exist in the basic Python distribution.\nGenerate data Just a sidenote here: If you\u0026rsquo;re wondering how I came up with the data in this video: We simulated it with Numpy functions! I sampled two random distributions 5000 times to create the height and weight arrays, and then used column_stack to paste them together as two columns. Another awesome thing that Numpy can do! Another great tool to get some sense of your data is to visualize it, but that\u0026rsquo;s something for the next course also.\n1# help(np.random.normal) 2#用于抽取服从正态分布的样本 3#arg1:样本均值；arg2:样本标准差；arg3:样本个数 4np_height_cm = np.round(np.random.normal(1.75,0.2,20),2) 5np_weight_kg = np.round(np.random.normal(60.32,15,20),2) 6# help(np.column_stack) 7# Stack 1-D arrays as columns into a 2-D array. 8# arg1:包含array的tup 9np_city = np.column_stack((np_height_cm,np_weight)) 10print(np.mean(np_height_cm)) 11print(np.median(np_height_cm)) 12print(np.std(np_height_cm)) 13print(np.corrcoef(np_city[:,0],np_city[:,1])) 1.8544999999999998 1.85 0.16524148994728896 [[1. 0.2840335] [0.2840335 1. ]]  Outlier however, you notice that some height values are abnormally high.\nMean value and median as summary statistic is best suited if you\u0026rsquo;re dealing with so-called outliers.\n1np_height_cm = np.array([1.64 ,1.49 ,1.79 ,18.4 ,20.7 ,177 ,1.72 ,1.61]) 2print(np.mean(np_height_cm)) 3print(np.median(np_height_cm)) 28.04375 1.755  Exercise You\u0026rsquo;ve contacted FIFA for some data and they handed you two lists. The lists are the following:\npositions = ['GK', 'M', 'A', 'D', ...] heights = [191, 184, 185, 180, ...]\nEach element in the lists corresponds to a player. The first list, positions, contains strings representing each player\u0026rsquo;s position. The possible positions are: 'GK' (goalkeeper), 'M' (midfield), 'A' (attack) and 'D' (defense). The second list, heights, contains integers representing the height of the player in cm. The first player in the lists is a goalkeeper and is pretty tall (191 cm).\nYou\u0026rsquo;re fairly confident that the median height of goalkeepers is higher than that of other players on the soccer field. Some of your friends don\u0026rsquo;t believe you, so you are determined to show them using the data you received from FIFA and your newly acquired Python skills.\n1heights = [191, 184, 185, 180, 181, 187, 170, 179, 183, 186, 185, 170, 187, 183, 173, 188, 183, 180, 188, 175, 193, 180, 185, 170, 183, 173, 185, 185, 168, 190] 2positions = [\u0026#39;GK\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;GK\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;GK\u0026#39;] 3np_positions = np.array(positions) 4np_heights = np.array(heights) 5gk_heights = np_heights[np_positions == \u0026#39;GK\u0026#39;] 6other_heights = np_heights[np_positions != \u0026#39;GK\u0026#39;] 7print(\u0026#34;Median height of goalkeepers: \u0026#34; + str(np.median(gk_heights))) 8print(\u0026#34;Median height of other players: \u0026#34; + str(np.median(other_heights))) Median height of goalkeepers: 191.0 Median height of other players: 183.0  Matplotlib There are many visualization packages in python, but the mother of them all, is matplotlib.\nMotivation Data visualization, which is a very important part of data analysis. First of all, you will use it to explore your dataset. The better you understand your data, the better you\u0026rsquo;ll be able to extract insights. And once you\u0026rsquo;ve found those insights, again, you\u0026rsquo;ll need visualization to be able to share your valuable insights with other people.\npyplot pyplot is a subpackage of Matplotlib\nBy convention, this subpackage is imported as plt\nimport matplotlib.pyplot as plt\nplot line chart(绘制折线图) we call plt.plot() and use our two lists as arguments.\nThe first argument corresponds to the horizontal axis, and the second one to the vertical axis.\nThere are several data points, and Python draws a line between them.\nIf you pass only one argument, Python will know what to do and will use the index of the list to map onto the x axis, and the values in the list onto the y axis.\nplt.show() You might think that a plot will pop up right now, but Python\u0026rsquo;s pretty lazy. It will wait for the show() function to actually display the plot. This is because you might want to add some extra ingredients to your plot before actually displaying it, such as titles and label customizations.\n1import matplotlib.pyplot as plt 2year = [1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100] 3pop = [2.53, 2.57, 2.62, 2.67, 2.71, 2.76, 2.81, 2.86, 2.92, 2.97, 3.03, 3.08, 3.14, 3.2, 3.26, 3.33, 3.4, 3.47, 3.54, 3.62, 3.69, 3.77, 3.84, 3.92, 4.0, 4.07, 4.15, 4.22, 4.3, 4.37, 4.45, 4.53, 4.61, 4.69, 4.78, 4.86, 4.95, 5.05, 5.14, 5.23, 5.32, 5.41, 5.49, 5.58, 5.66, 5.74, 5.82, 5.9, 5.98, 6.05, 6.13, 6.2, 6.28, 6.36, 6.44, 6.51, 6.59, 6.67, 6.75, 6.83, 6.92, 7.0, 7.08, 7.16, 7.24, 7.32, 7.4, 7.48, 7.56, 7.64, 7.72, 7.79, 7.87, 7.94, 8.01, 8.08, 8.15, 8.22, 8.29, 8.36, 8.42, 8.49, 8.56, 8.62, 8.68, 8.74, 8.8, 8.86, 8.92, 8.98, 9.04, 9.09, 9.15, 9.2, 9.26, 9.31, 9.36, 9.41, 9.46, 9.5, 9.55, 9.6, 9.64, 9.68, 9.73, 9.77, 9.81, 9.85, 9.88, 9.92, 9.96, 9.99, 10.03, 10.06, 10.09, 10.13, 10.16, 10.19, 10.22, 10.25, 10.28, 10.31, 10.33, 10.36, 10.38, 10.41, 10.43, 10.46, 10.48, 10.5, 10.52, 10.55, 10.57, 10.59, 10.61, 10.63, 10.65, 10.66, 10.68, 10.7, 10.72, 10.73, 10.75, 10.77, 10.78, 10.79, 10.81, 10.82, 10.83, 10.84, 10.85] 4plt.plot(year,pop) 5plt.show() Scatter plot The resulting scatter plot simply plots all the individual data points; Python doesn\u0026rsquo;t connect the dots with a line. For many applications, the scatter plot is often a better choice than the line plot, so remember this scatter function well. You could also say that this is a more -honest- way of plotting your data, because you can clearly see that the plot is based on just four data points.\nplt.xscale('log') Put the x-axis on a logarithmic scale(以对数形式显示x轴)\nA correlation will become clear when you display the GDP per capita on a logarithmic scale.\nyou saw that the higher GDP usually corresponds to a higher life expectancy. In other words, there is a positive correlation. there is not a relationship between population and life expectancy of a country\n1gdp_cap = [974.5803384, 5937.029525999998, 6223.367465, 4797.231267, 12779.37964, 34435.367439999995, 36126.4927, 29796.04834, 1391.253792, 33692.60508, 1441.284873, 3822.137084, 7446.298803, 12569.85177, 9065.800825, 10680.79282, 1217.032994, 430.0706916, 1713.778686, 2042.09524, 36319.23501, 706.016537, 1704.063724, 13171.63885, 4959.114854, 7006.580419, 986.1478792, 277.5518587, 3632.557798, 9645.06142, 1544.750112, 14619.222719999998, 8948.102923, 22833.30851, 35278.41874, 2082.4815670000007, 6025.3747520000015, 6873.262326000001, 5581.180998, 5728.353514, 12154.08975, 641.3695236000002, 690.8055759, 33207.0844, 30470.0167, 13206.48452, 752.7497265, 32170.37442, 1327.60891, 27538.41188, 5186.050003, 942.6542111, 579.2317429999998, 1201.637154, 3548.3308460000007, 39724.97867, 18008.94444, 36180.78919, 2452.210407, 3540.651564, 11605.71449, 4471.061906, 40675.99635, 25523.2771, 28569.7197, 7320.8802620000015, 31656.06806, 4519.461171, 1463.249282, 1593.06548, 23348.139730000006, 47306.98978, 10461.05868, 1569.331442, 414.5073415, 12057.49928, 1044.770126, 759.3499101, 12451.6558, 1042.581557, 1803.151496, 10956.99112, 11977.57496, 3095.7722710000007, 9253.896111, 3820.17523, 823.6856205, 944.0, 4811.060429, 1091.359778, 36797.93332, 25185.00911, 2749.320965, 619.6768923999998, 2013.977305, 49357.19017, 22316.19287, 2605.94758, 9809.185636, 4172.838464, 7408.905561, 3190.481016, 15389.924680000002, 20509.64777, 19328.70901, 7670.122558, 10808.47561, 863.0884639000002, 1598.435089, 21654.83194, 1712.472136, 9786.534714, 862.5407561000002, 47143.17964, 18678.31435, 25768.25759, 926.1410683, 9269.657808, 28821.0637, 3970.095407, 2602.394995, 4513.480643, 33859.74835, 37506.41907, 4184.548089, 28718.27684, 1107.482182, 7458.396326999998, 882.9699437999999, 18008.50924, 7092.923025, 8458.276384, 1056.380121, 33203.26128, 42951.65309, 10611.46299, 11415.80569, 2441.576404, 3025.349798, 2280.769906, 1271.211593, 469.70929810000007] 2life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 3pop = [31.889923, 3.600523, 33.333216, 12.420476, 40.301927, 20.434176, 8.199783, 0.708573, 150.448339, 10.392226, 8.078314, 9.119152, 4.552198, 1.639131, 190.010647, 7.322858, 14.326203, 8.390505, 14.131858, 17.696293, 33.390141, 4.369038, 10.238807, 16.284741, 1318.683096, 44.22755, 0.71096, 64.606759, 3.80061, 4.133884, 18.013409, 4.493312, 11.416987, 10.228744, 5.46812, 0.496374, 9.319622, 13.75568, 80.264543, 6.939688, 0.551201, 4.906585, 76.511887, 5.23846, 61.083916, 1.454867, 1.688359, 82.400996, 22.873338, 10.70629, 12.572928, 9.947814, 1.472041, 8.502814, 7.483763, 6.980412, 9.956108, 0.301931, 1110.396331, 223.547, 69.45357, 27.499638, 4.109086, 6.426679, 58.147733, 2.780132, 127.467972, 6.053193, 35.610177, 23.301725, 49.04479, 2.505559, 3.921278, 2.012649, 3.193942, 6.036914, 19.167654, 13.327079, 24.821286, 12.031795, 3.270065, 1.250882, 108.700891, 2.874127, 0.684736, 33.757175, 19.951656, 47.76198, 2.05508, 28.90179, 16.570613, 4.115771, 5.675356, 12.894865, 135.031164, 4.627926, 3.204897, 169.270617, 3.242173, 6.667147, 28.674757, 91.077287, 38.518241, 10.642836, 3.942491, 0.798094, 22.276056, 8.860588, 0.199579, 27.601038, 12.267493, 10.150265, 6.144562, 4.553009, 5.447502, 2.009245, 9.118773, 43.997828, 40.448191, 20.378239, 42.292929, 1.133066, 9.031088, 7.554661, 19.314747, 23.174294, 38.13964, 65.068149, 5.701579, 1.056608, 10.276158, 71.158647, 29.170398, 60.776238, 301.139947, 3.447496, 26.084662, 85.262356, 4.018332, 22.211743, 11.746035, 12.311143] 4plt.scatter(gdp_cap, life_exp) 5plt.xscale(\u0026#39;log\u0026#39;) 6plt.show() 7plt.clf() 8plt.scatter(pop, life_exp) 9# plt.xscale(\u0026#39;log\u0026#39;) 10plt.show() 11plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  histogram The histogram is a type of visualization that\u0026rsquo;s very useful to explore your data. It can help you to get an idea about the distribution of your variables.\nbin To build a histogram for these values, you can divide the line into equal chunks, called bins.Finally, you draw a bar for each bin.\nTo see how it works, imagine 12 values between 0 and 6.Suppose you go for 3 bins, that each have a width of 2. Next, you count how many data points sit inside each bin.There\u0026rsquo;s 4 data points in the first bin,6 in the second bin,and 2 in the third bin. Size of bin The number of bins is pretty important. Too few bins will oversimplify reality and won\u0026rsquo;t show you the details. Too many bins will overcomplicate reality and won\u0026rsquo;t show the bigger picture.\nplot histogram Finally, you draw a bar for each bin.The height of the bar corresponds to the number of data points that fall in this bin.\nyou can use the hist() function to plot a histogram\nThere\u0026rsquo;s a bunch of arguments you can specify, but the first two here are the most important ones. x should be a list of values you want to build a histogram for. You can use the second argument, bins, to tell Python into how many bins the data should be divided. Based on this number, hist will automatically find appropriate boundaries for all bins, and calculate how may values are in each one. If you don\u0026rsquo;t specify the bins argument, it will by 10 by default.\n1life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 2plt.hist(life_exp,5) 3plt.show() 4plt.clf() 5plt.hist(life_exp,20) 6plt.show() 7plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  line-plot VS scatter-plot VS histogram line-plot When you have a time scale along the horizontal axis, the line plot is your friend.\nscatter-plot But in many other cases, when you\u0026rsquo;re trying to assess if there\u0026rsquo;s a correlation between two variables, for example, the scatter plot is the better choice.\nscatter-plot It can help you to get an idea about the distribution of your variables.And it was very easy to make a comparison.\n1life_exp1950 = [28.8, 55.23, 43.08, 30.02, 62.48, 69.12, 66.8, 50.94, 37.48, 68.0, 38.22, 40.41, 53.82, 47.62, 50.92, 59.6, 31.98, 39.03, 39.42, 38.52, 68.75, 35.46, 38.09, 54.74, 44.0, 50.64, 40.72, 39.14, 42.11, 57.21, 40.48, 61.21, 59.42, 66.87, 70.78, 34.81, 45.93, 48.36, 41.89, 45.26, 34.48, 35.93, 34.08, 66.55, 67.41, 37.0, 30.0, 67.5, 43.15, 65.86, 42.02, 33.61, 32.5, 37.58, 41.91, 60.96, 64.03, 72.49, 37.37, 37.47, 44.87, 45.32, 66.91, 65.39, 65.94, 58.53, 63.03, 43.16, 42.27, 50.06, 47.45, 55.56, 55.93, 42.14, 38.48, 42.72, 36.68, 36.26, 48.46, 33.68, 40.54, 50.99, 50.79, 42.24, 59.16, 42.87, 31.29, 36.32, 41.72, 36.16, 72.13, 69.39, 42.31, 37.44, 36.32, 72.67, 37.58, 43.44, 55.19, 62.65, 43.9, 47.75, 61.31, 59.82, 64.28, 52.72, 61.05, 40.0, 46.47, 39.88, 37.28, 58.0, 30.33, 60.4, 64.36, 65.57, 32.98, 45.01, 64.94, 57.59, 38.64, 41.41, 71.86, 69.62, 45.88, 58.5, 41.22, 50.85, 38.6, 59.1, 44.6, 43.58, 39.98, 69.18, 68.44, 66.07, 55.09, 40.41, 43.16, 32.55, 42.04, 48.45] 2life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 3 4plt.hist(life_exp,15) 5plt.show() 6plt.clf() 7plt.hist(life_exp1950,15) 8plt.show() 9plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Customization Creating a plot is one thing. Making the correct plot, that makes the message very clear \u0026ndash; that\u0026rsquo;s the real challenge.\nData visualization For each visualization, you have many options. First of all, there are the different plot types. And for each plot, you can do an infinite number of customizations. You can change colors, shapes, labels, axes, and so on. The choice depends on: one, the data, and two, the story you want to tell with this data.\nAxis labels First, it should be clearer which data we are displaying, especially to people who are seeing the graph for the first time. And second, the plot really needs to draw the attention to the population explosion.\nThe first thing you always need to do is label your axes. Let\u0026rsquo;s do this by adding the xlabel() and ylabel() functions. As inputs, we pass strings that should be placed alongside the axes. Make sure to call these functions before calling the show function, otherwise your customizations will not be displayed.\nTitle We\u0026rsquo;re also going to add a title to our plot, with the title() function. We pass the actual title, \u0026lsquo;World Population Projections\u0026rsquo;, as an argument.\n1import matplotlib.pyplot as plt 2year = [1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100] 3pop = [2.53, 2.57, 2.62, 2.67, 2.71, 2.76, 2.81, 2.86, 2.92, 2.97, 3.03, 3.08, 3.14, 3.2, 3.26, 3.33, 3.4, 3.47, 3.54, 3.62, 3.69, 3.77, 3.84, 3.92, 4.0, 4.07, 4.15, 4.22, 4.3, 4.37, 4.45, 4.53, 4.61, 4.69, 4.78, 4.86, 4.95, 5.05, 5.14, 5.23, 5.32, 5.41, 5.49, 5.58, 5.66, 5.74, 5.82, 5.9, 5.98, 6.05, 6.13, 6.2, 6.28, 6.36, 6.44, 6.51, 6.59, 6.67, 6.75, 6.83, 6.92, 7.0, 7.08, 7.16, 7.24, 7.32, 7.4, 7.48, 7.56, 7.64, 7.72, 7.79, 7.87, 7.94, 8.01, 8.08, 8.15, 8.22, 8.29, 8.36, 8.42, 8.49, 8.56, 8.62, 8.68, 8.74, 8.8, 8.86, 8.92, 8.98, 9.04, 9.09, 9.15, 9.2, 9.26, 9.31, 9.36, 9.41, 9.46, 9.5, 9.55, 9.6, 9.64, 9.68, 9.73, 9.77, 9.81, 9.85, 9.88, 9.92, 9.96, 9.99, 10.03, 10.06, 10.09, 10.13, 10.16, 10.19, 10.22, 10.25, 10.28, 10.31, 10.33, 10.36, 10.38, 10.41, 10.43, 10.46, 10.48, 10.5, 10.52, 10.55, 10.57, 10.59, 10.61, 10.63, 10.65, 10.66, 10.68, 10.7, 10.72, 10.73, 10.75, 10.77, 10.78, 10.79, 10.81, 10.82, 10.83, 10.84, 10.85] 4plt.plot(year,pop) 5plt.xlabel(\u0026#34;Year\u0026#34;) 6plt.ylabel(\u0026#34;Population\u0026#34;) 7plt.title(\u0026#34;World Population Prediction\u0026#34;) 8plt.show() So, using xlabel, ylabel and title, we can give the reader more information about the data on the plot\nTicks To put the population growth in perspective, I want to have the y-axis start from zero.\nYou can do this with the yticks() function. The first input is a list, in this example with the numbers zero up to ten, with intervals of 2.(从0到10间隔为2的数字)If we run this, the plot will change: the curve shifts up.\n1plt.plot(year,pop) 2plt.xlabel(\u0026#34;Year\u0026#34;) 3plt.ylabel(\u0026#34;Population\u0026#34;) 4plt.title(\u0026#34;World Population Prediction\u0026#34;) 5plt.yticks([0, 2, 4, 6, 8, 10]) 6plt.show() names of the ticks Next, to make it clear we\u0026rsquo;re talking about billions, we can add a second argument to the yticks function, which is a list with the display names of the ticks. This list should have the same length as the first list. The tick 0 gets the name 0, the tick 2 gets the name 2B, the tick 4 gets the name 4B and so on. By the way, B stands for Billions here. If we run this version of the script,the labels will change accordingly.\n1plt.plot(year,pop) 2plt.xlabel(\u0026#34;Year\u0026#34;) 3plt.ylabel(\u0026#34;Population\u0026#34;) 4plt.title(\u0026#34;World Population Prediction\u0026#34;) 5plt.yticks([0, 2, 4, 6, 8, 10],\\ 6 [\u0026#39;0\u0026#39;, \u0026#39;2B\u0026#39;, \u0026#39;4B\u0026#39;, \u0026#39;6B\u0026#39;, \u0026#39;8B\u0026#39;, \u0026#39;10B\u0026#39;]) 7plt.show() Size of the scatter plot Right now, the scatter plot is just a cloud of blue dots, indistinguishable from each other. Let\u0026rsquo;s change this. Wouldn\u0026rsquo;t it be nice if the size of the dots corresponds to the population?\nYou can see that this list is added to the scatter() method, as the argument s, for size.\n1gdp_cap = [974.5803384, 5937.029525999998, 6223.367465, 4797.231267, 12779.37964, 34435.367439999995, 36126.4927, 29796.04834, 1391.253792, 33692.60508, 1441.284873, 3822.137084, 7446.298803, 12569.85177, 9065.800825, 10680.79282, 1217.032994, 430.0706916, 1713.778686, 2042.09524, 36319.23501, 706.016537, 1704.063724, 13171.63885, 4959.114854, 7006.580419, 986.1478792, 277.5518587, 3632.557798, 9645.06142, 1544.750112, 14619.222719999998, 8948.102923, 22833.30851, 35278.41874, 2082.4815670000007, 6025.3747520000015, 6873.262326000001, 5581.180998, 5728.353514, 12154.08975, 641.3695236000002, 690.8055759, 33207.0844, 30470.0167, 13206.48452, 752.7497265, 32170.37442, 1327.60891, 27538.41188, 5186.050003, 942.6542111, 579.2317429999998, 1201.637154, 3548.3308460000007, 39724.97867, 18008.94444, 36180.78919, 2452.210407, 3540.651564, 11605.71449, 4471.061906, 40675.99635, 25523.2771, 28569.7197, 7320.8802620000015, 31656.06806, 4519.461171, 1463.249282, 1593.06548, 23348.139730000006, 47306.98978, 10461.05868, 1569.331442, 414.5073415, 12057.49928, 1044.770126, 759.3499101, 12451.6558, 1042.581557, 1803.151496, 10956.99112, 11977.57496, 3095.7722710000007, 9253.896111, 3820.17523, 823.6856205, 944.0, 4811.060429, 1091.359778, 36797.93332, 25185.00911, 2749.320965, 619.6768923999998, 2013.977305, 49357.19017, 22316.19287, 2605.94758, 9809.185636, 4172.838464, 7408.905561, 3190.481016, 15389.924680000002, 20509.64777, 19328.70901, 7670.122558, 10808.47561, 863.0884639000002, 1598.435089, 21654.83194, 1712.472136, 9786.534714, 862.5407561000002, 47143.17964, 18678.31435, 25768.25759, 926.1410683, 9269.657808, 28821.0637, 3970.095407, 2602.394995, 4513.480643, 33859.74835, 37506.41907, 4184.548089, 28718.27684, 1107.482182, 7458.396326999998, 882.9699437999999, 18008.50924, 7092.923025, 8458.276384, 1056.380121, 33203.26128, 42951.65309, 10611.46299, 11415.80569, 2441.576404, 3025.349798, 2280.769906, 1271.211593, 469.70929810000007] 2life_exp = [43.828, 76.423, 72.301, 42.731, 75.32, 81.235, 79.829, 75.635, 64.062, 79.441, 56.728, 65.554, 74.852, 50.728, 72.39, 73.005, 52.295, 49.58, 59.723, 50.43, 80.653, 44.74100000000001, 50.651, 78.553, 72.961, 72.889, 65.152, 46.462, 55.322, 78.782, 48.328, 75.748, 78.273, 76.486, 78.332, 54.791, 72.235, 74.994, 71.33800000000002, 71.878, 51.57899999999999, 58.04, 52.947, 79.313, 80.657, 56.735, 59.448, 79.406, 60.022, 79.483, 70.259, 56.007, 46.38800000000001, 60.916, 70.19800000000001, 82.208, 73.33800000000002, 81.757, 64.69800000000001, 70.65, 70.964, 59.545, 78.885, 80.745, 80.546, 72.567, 82.603, 72.535, 54.11, 67.297, 78.623, 77.58800000000002, 71.993, 42.592, 45.678, 73.952, 59.44300000000001, 48.303, 74.241, 54.467, 64.164, 72.801, 76.195, 66.803, 74.543, 71.164, 42.082, 62.069, 52.90600000000001, 63.785, 79.762, 80.204, 72.899, 56.867, 46.859, 80.196, 75.64, 65.483, 75.53699999999998, 71.752, 71.421, 71.688, 75.563, 78.098, 78.74600000000002, 76.442, 72.476, 46.242, 65.528, 72.777, 63.062, 74.002, 42.56800000000001, 79.972, 74.663, 77.926, 48.159, 49.339, 80.941, 72.396, 58.556, 39.613, 80.884, 81.70100000000002, 74.143, 78.4, 52.517, 70.616, 58.42, 69.819, 73.923, 71.777, 51.542, 79.425, 78.242, 76.384, 73.747, 74.249, 73.422, 62.698, 42.38399999999999, 43.487] 3pop = [31.889923, 3.600523, 33.333216, 12.420476, 40.301927, 20.434176, 8.199783, 0.708573, 150.448339, 10.392226, 8.078314, 9.119152, 4.552198, 1.639131, 190.010647, 7.322858, 14.326203, 8.390505, 14.131858, 17.696293, 33.390141, 4.369038, 10.238807, 16.284741, 1318.683096, 44.22755, 0.71096, 64.606759, 3.80061, 4.133884, 18.013409, 4.493312, 11.416987, 10.228744, 5.46812, 0.496374, 9.319622, 13.75568, 80.264543, 6.939688, 0.551201, 4.906585, 76.511887, 5.23846, 61.083916, 1.454867, 1.688359, 82.400996, 22.873338, 10.70629, 12.572928, 9.947814, 1.472041, 8.502814, 7.483763, 6.980412, 9.956108, 0.301931, 1110.396331, 223.547, 69.45357, 27.499638, 4.109086, 6.426679, 58.147733, 2.780132, 127.467972, 6.053193, 35.610177, 23.301725, 49.04479, 2.505559, 3.921278, 2.012649, 3.193942, 6.036914, 19.167654, 13.327079, 24.821286, 12.031795, 3.270065, 1.250882, 108.700891, 2.874127, 0.684736, 33.757175, 19.951656, 47.76198, 2.05508, 28.90179, 16.570613, 4.115771, 5.675356, 12.894865, 135.031164, 4.627926, 3.204897, 169.270617, 3.242173, 6.667147, 28.674757, 91.077287, 38.518241, 10.642836, 3.942491, 0.798094, 22.276056, 8.860588, 0.199579, 27.601038, 12.267493, 10.150265, 6.144562, 4.553009, 5.447502, 2.009245, 9.118773, 43.997828, 40.448191, 20.378239, 42.292929, 1.133066, 9.031088, 7.554661, 19.314747, 23.174294, 38.13964, 65.068149, 5.701579, 1.056608, 10.276158, 71.158647, 29.170398, 60.776238, 301.139947, 3.447496, 26.084662, 85.262356, 4.018332, 22.211743, 11.746035, 12.311143] 4plt.scatter(gdp_cap,life_exp,s = pop) 5plt.xscale(\u0026#39;log\u0026#39;) 6plt.xlabel(\u0026#39;GDP per Capita [in USD]\u0026#39;) 7plt.ylabel(\u0026#39;Life Expectancy [in years]\u0026#39;) 8plt.title(\u0026#39;World Development in 2007\u0026#39;) 9plt.xticks([1000, 10000, 100000],[\u0026#39;1k\u0026#39;, \u0026#39;10k\u0026#39;, \u0026#39;100k\u0026#39;]) 10plt.show() 11plt.clf() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;  Colors The next step is making the plot more colorful! To do this, a list col has been created for you. It\u0026rsquo;s a list with a color for each corresponding country, depending on the continent the country is part of.\nHow did we make the list col you ask? The Gapminder data contains a list continent with the continent each country belongs to. A dictionary is constructed that maps continents onto colors:\n1dict = { 2 \u0026#39;Asia\u0026#39;:\u0026#39;red\u0026#39;, 3 \u0026#39;Europe\u0026#39;:\u0026#39;green\u0026#39;, 4 \u0026#39;Africa\u0026#39;:\u0026#39;blue\u0026#39;, 5 \u0026#39;Americas\u0026#39;:\u0026#39;yellow\u0026#39;, 6 \u0026#39;Oceania\u0026#39;:\u0026#39;black\u0026#39; 7} Opacity of plot Change the opacity of the bubbles by setting the alpha argument\nAlpha can be set from zero to one, where zero is totally transparent, and one is not at all transparent.\nText text() function can add the words into the plot.\ngridiness(网格) grid() function can draw the gridiness into the plot.\n1col = [\u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;black\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;black\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;blue\u0026#39;] 2plt.figure(dpi=300) 3plt.scatter(gdp_cap,life_exp,s = pop,c = col,alpha = 0.8) 4plt.xscale(\u0026#39;log\u0026#39;) 5plt.xlabel(\u0026#39;GDP per Capita [in USD]\u0026#39;) 6plt.ylabel(\u0026#39;Life Expectancy [in years]\u0026#39;) 7plt.title(\u0026#39;World Development in 2007\u0026#39;) 8plt.xticks([1000, 10000, 100000],[\u0026#39;1k\u0026#39;, \u0026#39;10k\u0026#39;, \u0026#39;100k\u0026#39;]) 9plt.text(1550, 71, \u0026#39;India\u0026#39;) 10plt.text(5700, 80, \u0026#39;China\u0026#39;) 11plt.grid(True) 12plt.show() Pandas Pandas is a high level data manipulation tool developed by Wes McKinney, built on the Numpy and matplotlib package,providing high-performance, easy-to-use data structures and data analysis tools for Python.\nCompared to Numpy, it\u0026rsquo;s more high level, making it very interesting for data scientists all over the world.\nIn pandas, we store the tabular data like the brics table here in an object called a DataFrame.\nMotivation As a data scientist, you\u0026rsquo;ll often be working with tons of data. The form of this data can vary greatly, but pretty often, you can boil it down to a tabular structure, that is, in the form of a table like in a spreadsheet.\n2D numpy array? Well, it\u0026rsquo;s an option, but not necessarily the best one. In the two examples we covered, there are different data types and Numpy arrays are not great at handling these.\nnumpy数组为了加速运算只允许存储一种数据类型，然而大多数情况下我们的数据集包含多种不同的数据类型\nTabular dataset examples This data can come in the following form:\nEvery row is a measurement, or an observation, and for each observation, there are different variables.\nDataFrame The DataFrame is one of Pandas' most important data structures. It\u0026rsquo;s basically a way to store tabular data where you can label the rows and the columns.\nAlso notice that each row and column has a unique label(行和列都有唯一的标签)\nNotice that the values in the different columns have different types.(不同列的值可以是不同的数据类型)\nHow to build DataFrame DataFrame from Dictionary The keys are the column labels, and the values are the corresponding columns, in list form.\nAfter importing the pandas package as pd, you can create a DataFrame from the dictionary using pd.DataFrame().\nPandas assigned some automatic row labels,to specify them manually, you can set the index attribute to a list with the correct labels.(手动指定列标签：将DataFrame的index属性设置为带有标签的List)\n1import pandas as pd 2dict = { \u0026#34;country\u0026#34;:[\u0026#34;Brazil\u0026#34;, \u0026#34;Russia\u0026#34;, \u0026#34;India\u0026#34;, \u0026#34;China\u0026#34;, \u0026#34;South Africa\u0026#34;],\\ 3 \u0026#34;capital\u0026#34;:[\u0026#34;Brasilia\u0026#34;, \u0026#34;Moscow\u0026#34;, \u0026#34;New Delhi\u0026#34;, \u0026#34;Beijing\u0026#34;, \u0026#34;Pretoria\u0026#34;],\\ 4 \u0026#34;area\u0026#34;:[8.516, 17.10, 3.286, 9.597, 1.221],\\ 5 \u0026#34;population\u0026#34;:[200.4, 143.5, 1252, 1357, 52.98] } 6brics = pd.DataFrame(dict) 7print(brics) 8brics.index = [\u0026#39;BR\u0026#39;,\u0026#39;RU\u0026#39;,\u0026#39;IN\u0026#39;,\u0026#39;CH\u0026#39;,\u0026#39;SA\u0026#39;] 9print(brics)  country capital area population 0 Brazil Brasilia 8.516 200.40 1 Russia Moscow 17.100 143.50 2 India New Delhi 3.286 1252.00 3 China Beijing 9.597 1357.00 4 South Africa Pretoria 1.221 52.98 country capital area population BR Brazil Brasilia 8.516 200.40 RU Russia Moscow 17.100 143.50 IN India New Delhi 3.286 1252.00 CH China Beijing 9.597 1357.00 SA South Africa Pretoria 1.221 52.98  DataFrame from external file Using a dictionary approach is fine, but what if you\u0026rsquo;re working with tons of data, which is typically the case as a data scientist?\nIn those cases, the data is typically available as files with a regular structure. One of those file types is the CSV file, which is short for \u0026ldquo;comma-separated values\u0026rdquo;\nInstead, you import data from an external file that contains all this data.\nCSV File CSV is short for comma separated values.(CSV是以逗号分隔数组的缩写)\nimport from .CSV file we can do this by using Pandas read_csv() function,You pass the path to the csv file as an argument.\nthere\u0026rsquo;s still something wrong. The row labels are seen as a column in their own right. To solve this, we\u0026rsquo;ll have to tell the read_csv function that the first column contains the row indexes. You do this by setting the index_col argument inside pd.read_csv.\nThis time it makes sure that the rows and columns are given appropriate labels. This is important to make accessing columns, rows and single elements in your DataFrame easy.\nThe read_csv function features many more arguments that allow you to customize your data import, make sure to check out its documentation\n1import pandas as pd 2brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;) 3print(brics) 4brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;,index_col = 0) 5print(brics) 6  Unnamed: 0 country capital area population 0 BR Brazil Brasilia 8.516 200.40 1 RU Russia Moscow 17.100 143.50 2 IN India New Delhi 3.286 1252.00 3 CH China Beijing 9.597 1357.00 4 SA South Africa Pretoria 1.221 52.98 country capital area population BR Brazil Brasilia 8.516 200.40 RU Russia Moscow 17.100 143.50 IN India New Delhi 3.286 1252.00 CH China Beijing 9.597 1357.00 SA South Africa Pretoria 1.221 52.98  Index and select data There are numerous ways in which you can index and select data from DataFrames.\nColumn Access [ ] Suppose that you only want to select a column from DataFrame.\nyou type the column label inside square brackets.\nBut there\u0026rsquo;s something strange here. The last line says Name: country, dtype: object.\nSo we\u0026rsquo;re dealing with a Pandas Series here\nSeries type of Pandas In a simplified sense, you can think of the Series as a 1-dimensional array that can be labeled, just like the DataFrame. Otherwise put, if you paste together a bunch of Series, you can create a DataFrame.\n1country = brics[\u0026#34;country\u0026#34;] 2print(country) 3print(type(country)) BR Brazil RU Russia IN India CH China SA South Africa Name: country, dtype: object \u0026lt;class 'pandas.core.series.Series'\u0026gt;  Selete data but keep the data in a DataFrame you\u0026rsquo;ll need double square brackets.\nIf you look at it from a different angle, you\u0026rsquo;re actually putting a list with column labels inside another set of square bracket\n1country = brics[[\u0026#34;country\u0026#34;]] 2print(country) 3print(type(country))  country BR Brazil RU Russia IN India CH China SA South Africa \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; country capital BR Brazil Brasilia RU Russia Moscow IN India New Delhi CH China Beijing SA South Africa Pretoria \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  1capital = brics[[\u0026#34;country\u0026#34;,\u0026#34;capital\u0026#34;]] 2print(capital) 3print(type(capital))  country capital BR Brazil Brasilia RU Russia Moscow IN India New Delhi CH China Beijing SA South Africa Pretoria \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  Row Access [ ] The way to do it is by specifying a slice.To get the second, third and fourth rows of brics, we use the slice 1 colon 4. Remember that the end of the slice is exclusive and that the index starts at zero.\n1print(brics[1:4]) 2print(type(brics[1:4]))  country capital area population RU Russia Moscow 17.100 143.5 IN India New Delhi 3.286 1252.0 CH China Beijing 9.597 1357.0 \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  Adanced methods These square brackets work, but it only offers limited functionality. Ideally, we\u0026rsquo;d want something similar to 2D Numpy arrays. There, you also used square brackets, the index or slice before the comma referred to the rows, the index or slice after the comma referred to the columns. If we want to do a similar thing with Pandas, we have to extend our toolbox with the loc() and iloc() functions.\nloc(advanced method) loc is label-based, which means that you have to specify rows and columns based on their row and column labels.\nYou put the label of the row of interest in square brackets after loc.we get a Pandas Series, containing all the row\u0026rsquo;s information, rather inconveniently shown on different lines.(series信息单独在一列上显示，很不方便)\nTo get a data frame, we have to put list which include the labels inside another pair of brackets.\nWe can also select multiple rows at the same time.This will do the trick; simply add some more row labels to the list.\n1CH = brics.loc[\u0026#39;CH\u0026#39;] 2print(CH) 3print(type(CH)) country China capital Beijing area 9.597 population 1357 Name: CH, dtype: object \u0026lt;class 'pandas.core.series.Series'\u0026gt;  1DF_CH = brics.loc[[\u0026#39;CH\u0026#39;]] 2print(DF_CH) 3print(type(DF_CH))  country capital area population CH China Beijing 9.597 1357.0 \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt;  1print(brics.loc[[\u0026#39;CH\u0026#39;,\u0026#39;IN\u0026#39;]])  country capital area population CH China Beijing 9.597 1357.0 IN India New Delhi 3.286 1252.0  This was only selecting entire rows, that\u0026rsquo;s something you could also do with the basic square brackets. The difference here is that you can extend your selection with a comma and a specification of the columns of interest.\n(用这种在方括号中输入list的方法，我们还可以在列标签的list后，加上逗号，和行标签的list。这样就不用选取一整行)\nWe add a comma, and a list of column labels we want to keep. The intersection gets returned.\nOf course, you can also use loc to select all rows but only a specific number of columns.\nSimply replace the first list that specifies the row labels with a colon, a slice going from beginning to end. This time, the intersection spans all rows\n1print(brics.loc[[\u0026#39;CH\u0026#39;,\u0026#39;IN\u0026#39;],[\u0026#39;country\u0026#39;,\u0026#39;capital\u0026#39;]])  country capital CH China Beijing IN India New Delhi  1print(brics.loc[:,[\u0026#39;country\u0026#39;,\u0026#39;capital\u0026#39;]])  country capital BR Brazil Brasilia RU Russia Moscow IN India New Delhi CH China Beijing SA South Africa Pretoria  iloc(advanced method) iloc is integer index based, so you have to specify rows and columns by their integer index\nloc and iloc are pretty similar, the only difference is how you refer to columns and rows.you can keep all rows or columns in a similar fashion.\n1print(brics.iloc[3]) country China capital Beijing area 9.597 population 1357 Name: CH, dtype: object  1print(brics.iloc[[2,3]])  country capital area population IN India New Delhi 3.286 1252.0 CH China Beijing 9.597 1357.0  1print(brics.iloc[[2,3],[0,1]])  country capital IN India New Delhi CH China Beijing  square bracket VS loc() or iloc() square bracket simple square brackets work fine if you want to get columns; to get rows, you can use slicing.\n只想整行或者整列筛选，可以使用简单的方括号\nloc() or iloc() The loc function is more versatile: you can select rows, columns, but also rows and columns at the same time. When you use loc, subsetting becomes remarkable similar to how you subsetted 2D Numpy arrays.\n即想进行行筛选，又想进行列筛选，可以选择loc()\nFiltering pandas DataFrames illustration Suppose you now want to keep the countries, so the observations in this case, for which the area is greater than 8 million square kilometers.\nThere are three steps to this:\nFirst of all, we want to get the area column from brics.\nNext, we perform the comparison on this column and store its result.\nFinally, we should use this result to do the appropriate selection on the DataFrame.\nGet column There are many different ways to do this. What\u0026rsquo;s important here, is that we ideally get a Pandas Series, not a Pandas DataFrame.(必须用Series数据类型)\nCompare Next, we actually perform the comparison.we simply use comparsion operator in this.Now we get a Series containing booleans or Boolean Series.\nsubset DataFrame The final step is using this boolean Series to subset the Pandas DataFrame.you put Boolen Series inside square brackets.so we can get a DataFrame that conform the condition.\n1print(brics[brics[\u0026#39;area\u0026#39;]\u0026gt;8])  country capital area population BR Brazil Brasilia 8.516 200.4 RU Russia Moscow 17.100 143.5 CH China Beijing 9.597 1357.0  Boolean operators Because Pandas is built on Numpy, you can also use that function here.\n1import numpy as np 2print(brics[np.logical_and(brics[\u0026#39;area\u0026#39;]\u0026gt;8,brics[\u0026#39;area\u0026#39;]\u0026lt;10)])  country capital area population BR Brazil Brasilia 8.516 200.4 CH China Beijing 9.597 1357.0  Loop Data Structures 1D numpy array It is just same as list.\n2D numpy array To get every element of an array, you can use a Numpy function called nditer().\n1import numpy as np 2np_height = np.array([1.73, 1.68, 1.71, 1.89, 1.79]) 3np_weight = np.array([65.4, 59.2, 63.6, 88.4, 68.7]) 4meas = np.array([np_height, np_weight]) 5for x in np.nditer(meas): 6 print(x) 1.73 1.68 1.71 1.89 1.79 65.4 59.2 63.6 88.4 68.7  Loop for Pandas DataFrame Loop over row labels a basic for loop simply got the column names.\n1brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;,index_col=0) 2for x in brics : 3 print(x) country capital area population  Loop over row In Pandas,if you want to iterate over each row,you have to mention explicitly.\nYou do this by calling the iterrows() method\nThe iterrows() method looks at the data frame, and on each iteration generates two pieces of data: the label of the row and then the actual data in the row as a Pandas Series.\n1for lab,row in brics.iterrows(): 2 print(lab) 3 print(row) BR country Brazil capital Brasilia area 8.516 population 200.4 Name: BR, dtype: object RU country Russia capital Moscow area 17.1 population 143.5 Name: RU, dtype: object IN country India capital New Delhi area 3.286 population 1252 Name: IN, dtype: object CH country China capital Beijing area 9.597 population 1357 Name: CH, dtype: object SA country South Africa capital Pretoria area 1.221 population 52.98 Name: SA, dtype: object  Add column we need to iterate over the row,so we can get both the row label and the row data.\nwe\u0026rsquo;ll have to add this new information to a new column at the appropriate location.\n1for lab,row in brics.iterrows(): 2 brics.loc[lab,\u0026#39;name_length\u0026#39;] = len(row[\u0026#39;country\u0026#39;]) 3print(brics)  country capital area population name_length BR Brazil Brasilia 8.516 200.40 6.0 RU Russia Moscow 17.100 143.50 6.0 IN India New Delhi 3.286 1252.00 5.0 CH China Beijing 9.597 1357.00 5.0 SA South Africa Pretoria 1.221 52.98 12.0  apply() You can vectorized operations with the apply function\nPrevious method was not especially efficient , because you\u0026rsquo;re creating a Series object on every iteration. For this small DataFrame that doesn\u0026rsquo;t matter, but if you\u0026rsquo;re doing funky stuff on a ginormous dataset, this loss in efficiency can become problematic.\nIf you want to add a column to a DataFrame by calling a function on another column, the iterrows() method in combination with a for loop is not the preferred way to go.\nA way better approach if you want to calculate an entire DataFrame column by applying a function on a particular column in an element-wise fashion, is apply().\nBasically, you\u0026rsquo;re selecting the column from the DataFrame, and then, on this column, you apply the len function.\nApply calls the function with each value as input and produces a new array, that you can easily store as a new column\n1brics = pd.read_csv(\u0026#34;./brics.csv\u0026#34;,index_col=0) 2brics[\u0026#39;name_length\u0026#39;] = brics[\u0026#39;country\u0026#39;].apply(len) 3brics .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  1i=73 2print(id(i)) 3i+=2 4print(id(i)) 4483145248 4483145312 ","date":"Jan 1, 0001","img":"","permalink":"/en/tutorialnotebook/","series":null,"tags":null,"title":""}]